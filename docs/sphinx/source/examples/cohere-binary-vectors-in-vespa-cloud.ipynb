{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d551cc4e",
            "metadata": {
                "id": "b3ae8a2b"
            },
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "0dd50339",
            "metadata": {},
            "source": [
                "<picture>\n",
                "  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg\">\n",
                "  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\">\n",
                "  <img alt=\"#Vespa\" width=\"200\" src=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\" style=\"margin-bottom: 25px;\">\n",
                "</picture>\n",
                "\n",
                "# Using Cohere Binary Embeddings in Vespa\n",
                "\n",
                "Cohere just released a new embedding API supporting binary and `int8` vectors.\n",
                "Read the announcement in the blog post: [Cohere int8 & binary Embeddings - Scale Your Vector Database to Large Datasets](https://cohere.com/blog/int8-binary-embeddings).\n",
                "\n",
                "> We are excited to announce that Cohere Embed is the first embedding model that natively supports int8 and binary embeddings.\n",
                "\n",
                "This is significant because:\n",
                "\n",
                "- Binarization reduces the storage footprint from 1024 floats (4096 bytes) per vector to 128 int8 (128 bytes).\n",
                "- 32x less data to store\n",
                "- Faster distance calculations using [hamming](https://docs.vespa.ai/en/reference/schema-reference.html#distance-metric) distance, which\n",
                "  Vespa natively supports for bits packed into int8 precision. More on [hamming distance in Vespa](https://docs.vespa.ai/en/reference/schema-reference.html#hamming).\n",
                "\n",
                "Vespa supports `hamming` distance with and without [hnsw indexing](https://docs.vespa.ai/en/approximate-nn-hnsw.html).\n",
                "\n",
                "For those wanting to learn more about binary vectors, we recommend our 2021 blog series on [Billion-scale vector search with Vespa](https://blog.vespa.ai/billion-scale-knn/)\n",
                "and [Billion-scale vector search with Vespa - part two](https://blog.vespa.ai/billion-scale-knn-part-two/).\n",
                "\n",
                "![img](https://blog.vespa.ai/assets/2022-01-27-billion-scale-knn-part-two/throughput.png)\n",
                "\n",
                "This notebook demonstrates how to use the Cohere binary vectors with Vespa, including\n",
                "a re-ranking phase that uses the float query vector version for improved accuracy. From the Cohere blog announcement:\n",
                "\n",
                "> To improve the search quality, the float query embedding can be compared with the binary document embeddings using dot-product. So we first retrieve 10\\*top_k results with the binary query embedding, and then rescore the binary document embeddings with the float query embedding. This pushes the search quality from 90% to 95%.\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vespa-engine/pyvespa/blob/master/docs/sphinx/source/examples/cohere-binary-vectors-in-vespa-cloud.ipynb)\n",
                "\n",
                "Install the dependencies:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "daf34cf5",
            "metadata": {
                "id": "4ffa3cbe"
            },
            "outputs": [],
            "source": [
                "!pip3 install -U pyvespa cohere==4.57 vespacli"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b3f11700",
            "metadata": {},
            "source": [
                "## Examining the Cohere embeddings\n",
                "\n",
                "Let us check out the Cohere embedding API and how we can obtain binarized embeddings. See also the [Cohere embed API doc](https://docs.cohere.com/docs/embed-api).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "e2371493",
            "metadata": {},
            "outputs": [],
            "source": [
                "import cohere\n",
                "\n",
                "# Make sure that the environment variable CO_API_KEY is set to your API key\n",
                "co = cohere.Client()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3b68ebc1",
            "metadata": {},
            "source": [
                "### Some sample documents\n",
                "\n",
                "Define a few sample documents that we want to embed\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "c9b35db3",
            "metadata": {},
            "outputs": [],
            "source": [
                "documents = [\n",
                "    \"Alan Turing  was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.\",\n",
                "    \"Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.\",\n",
                "    \"Isaac Newton was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author who was described in his time as a natural philosopher.\",\n",
                "    \"Marie Curie was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity\",\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "803d1a4d",
            "metadata": {},
            "source": [
                "Notice that we ask for `embedding_types=[\"binary]`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "d4edb2c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute the binary embeddings ofdocuments.\n",
                "# Set input_type to \"search_document\" and embedding_types to \"binary\"\n",
                "\n",
                "cohere_response = co.embed(\n",
                "    documents,\n",
                "    model=\"embed-english-v3.0\",\n",
                "    input_type=\"search_document\",\n",
                "    embedding_types=[\"binary\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "837c5ab4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[-110, 121, 110, -50, 87, -59, 8, 35, 114, 30, -92, -112, -118, -16, 7, 96, 17, 51, 97, -9, -23, 25, -103, -35, -78, -47, 64, -123, -41, 67, 14, -31, -42, -126, 75, 111, 62, -64, 57, 64, -52, -66, -64, -12, 100, 99, 87, 61, -5, 5, 23, 34, -75, -66, -16, 91, 92, 121, 55, 117, 100, -112, -24, 84, 84, -65, 61, -31, -45, 7, 44, 8, -35, -125, 16, -50, -52, 11, -105, -32, 102, -62, -3, 86, -107, 21, 95, 15, 27, -79, -20, 114, 90, 125, 110, -97, -15, -98, 21, -102, -124, 112, -115, 26, -86, -55, 67, 7, 11, -127, 125, 103, -46, -55, 79, -31, 126, -32, 33, -128, -124, -80, 21, 27, -49, -9, 112, 101], [-110, -7, -24, 23, -33, 68, 24, 35, 22, -50, -32, 86, 74, -14, 71, 96, 81, -45, 105, -25, -73, 108, -99, 13, -76, 125, 73, -44, -34, -34, -105, 75, 86, -58, 85, -30, -92, -27, -39, 0, -75, -2, 30, -12, -116, 9, 81, 39, 76, 44, 87, 20, -43, 110, -75, 20, 108, 125, -75, 85, -28, -118, -24, 127, 78, -75, 108, -20, -48, 3, 12, 12, 71, -29, -98, -26, 68, 11, 0, -104, 96, 70, -3, 53, -98, -108, 127, -102, -17, -84, -88, 88, -54, -45, -11, -4, -4, 15, -67, 122, -108, 117, -51, 40, 98, -47, 102, -103, 3, -123, -85, 119, -48, -24, 95, -34, -26, -24, -31, -9, 99, 64, -128, -43, 74, -91, 80, -95], [64, -14, -4, 30, 118, 5, 8, 35, 51, 3, 72, -122, -70, -10, 2, -20, 17, 115, -67, -9, 115, 31, -103, -73, -78, 65, 64, -123, -41, 91, 14, -39, -41, -78, 73, -62, 60, -28, 89, 32, 33, -35, -62, 116, 102, -45, 83, 63, 73, 37, 23, 64, -43, -46, -106, 83, 109, 92, -87, -15, -60, -39, -23, 63, 84, 56, -6, -15, 20, 3, 76, 3, 104, -16, -79, 70, -123, 15, -125, -111, 109, -105, -99, 82, -19, -27, 95, -113, 94, -74, 57, 82, -102, -7, -95, -21, -3, -66, 73, 95, -124, 37, -115, -81, 107, -55, -25, 6, 19, -107, -120, 111, -110, -23, 79, -26, 106, -61, -96, -77, 9, 116, -115, -67, -63, -9, -43, 77], [-109, -7, -32, 19, 87, 116, 8, 35, 54, -102, -64, -106, -14, -10, 31, 78, -99, 59, -6, -45, 97, 96, -103, 37, 69, -35, -119, -59, 95, 27, 14, 73, 86, -9, -43, 110, -70, 96, 45, 32, -91, 62, -64, -12, 100, -55, 34, 62, 14, 5, 22, 67, -75, -17, -14, 81, 45, 125, -15, -11, -28, 75, -25, 20, 42, -78, -4, -67, -44, 11, 76, 3, 127, 40, 0, 103, 75, -62, -123, -111, 64, -13, -10, -5, -66, -89, 119, -70, -29, -95, -19, 82, 106, 127, -24, -11, -48, 15, -29, -102, -115, 107, -115, 55, -69, -61, 103, 11, 3, 25, -118, 63, -108, 11, 78, -28, 14, 124, 119, -61, 97, 84, 53, 69, 123, 89, -104, -127]]\n"
                    ]
                }
            ],
            "source": [
                "print(cohere_response.embeddings.binary)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "72ec8cf4",
            "metadata": {},
            "source": [
                "As we can see from the above, we got an array of binary embeddings, using signed `int8` precision in the numeric range [-128 to 127]. Each embedding vector\n",
                "has 128 dimensions:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "20baafcb",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "128"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(cohere_response.embeddings.binary[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "74ec69ca",
            "metadata": {
                "id": "da356d25"
            },
            "source": [
                "## Defining the Vespa application\n",
                "\n",
                "First, we define a [Vespa schema](https://docs.vespa.ai/en/schemas.html) with the fields we want to store and their type.\n",
                "\n",
                "Notice the `binary_vector` field that defines an indexed (dense) Vespa tensor with the dimension name `x[128]`. Indexing specifies `index`\n",
                "which means that Vespa will use HNSW indexing for this field. Also notice the configuration of [distance-metric](https://docs.vespa.ai/en/reference/schema-reference.html#distance-metric)\n",
                "where we specify `hamming`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "29105961",
            "metadata": {
                "executionInfo": {
                    "elapsed": 224,
                    "status": "ok",
                    "timestamp": 1706652002196,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "0dca2378"
            },
            "outputs": [],
            "source": [
                "from vespa.package import Schema, Document, Field, FieldSet\n",
                "\n",
                "my_schema = Schema(\n",
                "    name=\"doc\",\n",
                "    mode=\"index\",\n",
                "    document=Document(\n",
                "        fields=[\n",
                "            Field(\n",
                "                name=\"doc_id\",\n",
                "                type=\"string\",\n",
                "                indexing=[\"summary\", \"index\"],\n",
                "                match=[\"word\"],\n",
                "                rank=\"filter\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"text\",\n",
                "                type=\"string\",\n",
                "                indexing=[\"summary\", \"index\"],\n",
                "                index=\"enable-bm25\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"binary_vector\",\n",
                "                type=\"tensor<int8>(x[128])\",\n",
                "                indexing=[\"attribute\", \"index\"],\n",
                "                attribute=[\"distance-metric: hamming\"],\n",
                "            ),\n",
                "        ]\n",
                "    ),\n",
                "    fieldsets=[FieldSet(name=\"default\", fields=[\"text\"])],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bed768cb",
            "metadata": {},
            "source": [
                "We must add the schema to a Vespa [application package](https://docs.vespa.ai/en/application-packages.html).\n",
                "This consists of configuration files, schemas, models, and possibly even custom code (plugins).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "c371b01f",
            "metadata": {
                "executionInfo": {
                    "elapsed": 239,
                    "status": "ok",
                    "timestamp": 1706652007584,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "66c5da1d"
            },
            "outputs": [],
            "source": [
                "from vespa.package import ApplicationPackage\n",
                "\n",
                "vespa_app_name = \"cohere\"\n",
                "vespa_application_package = ApplicationPackage(name=vespa_app_name, schema=[my_schema])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9a3fe087",
            "metadata": {
                "id": "7fe3d7bd"
            },
            "source": [
                "In the last step, we configure [ranking](https://docs.vespa.ai/en/ranking.html) by adding `rank-profile`'s to the schema.\n",
                "\n",
                "`unpack_bits` unpacks the binary representation into a 1024-dimensional float vector [doc](https://docs.vespa.ai/en/reference/ranking-expressions.html#unpack-bits).\n",
                "\n",
                "We define two tensor inputs, one compact binary representation that is used for the nearestNeighbor search and one\n",
                "full version that is used in ranking.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "a5d13c7f",
            "metadata": {
                "executionInfo": {
                    "elapsed": 407,
                    "status": "ok",
                    "timestamp": 1706652010412,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "a8ce5624"
            },
            "outputs": [],
            "source": [
                "from vespa.package import RankProfile, FirstPhaseRanking, SecondPhaseRanking, Function\n",
                "\n",
                "\n",
                "rerank = RankProfile(\n",
                "    name=\"rerank\",\n",
                "    inputs=[\n",
                "        (\"query(q_binary)\", \"tensor<int8>(x[128])\"),\n",
                "        (\"query(q_full)\", \"tensor<float>(x[1024])\"),\n",
                "    ],\n",
                "    functions=[\n",
                "        Function(  # this returns a tensor<float>(x[1024]) with values -1 or 1\n",
                "            name=\"unpack_binary_representation\",\n",
                "            expression=\"2*unpack_bits(attribute(binary_vector)) -1\",\n",
                "        )\n",
                "    ],\n",
                "    first_phase=FirstPhaseRanking(\n",
                "        expression=\"closeness(field, binary_vector)\"  # 1/(1 + hamming_distance). Calculated between the binary query and the binary_vector\n",
                "    ),\n",
                "    second_phase=SecondPhaseRanking(\n",
                "        expression=\"sum( query(q_full)* unpack_binary_representation )\",  # re-rank using the dot product between float query and the unpacked binary representation\n",
                "        rerank_count=100,\n",
                "    ),\n",
                "    match_features=[\n",
                "        \"distance(field, binary_vector)\",\n",
                "        \"closeness(field, binary_vector)\",\n",
                "    ],\n",
                ")\n",
                "my_schema.add_rank_profile(rerank)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c46c95aa",
            "metadata": {
                "id": "846545f9"
            },
            "source": [
                "## Deploy the application to Vespa Cloud\n",
                "\n",
                "With the configured application, we can deploy it to [Vespa Cloud](https://cloud.vespa.ai/en/).\n",
                "\n",
                "To deploy the application to Vespa Cloud we need to create a tenant in the Vespa Cloud:\n",
                "\n",
                "Create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/) (unless you already have one).\n",
                "This step requires a Google or GitHub account, and will start your [free trial](https://cloud.vespa.ai/en/free-trial).\n",
                "\n",
                "Make note of the tenant name, it is used in the next steps.\n",
                "\n",
                "> Note: Deployments to dev and perf expire after 7 days of inactivity, i.e., 7 days after running deploy. This applies to all plans, not only the Free Trial. Use the Vespa Console to extend the expiry period, or redeploy the application to add 7 more days.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "3a11f211",
            "metadata": {
                "executionInfo": {
                    "elapsed": 339,
                    "status": "ok",
                    "timestamp": 1706652019048,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "b5fddf9f"
            },
            "outputs": [],
            "source": [
                "from vespa.deployment import VespaCloud\n",
                "import os\n",
                "\n",
                "# Replace with your tenant name from the Vespa Cloud Console\n",
                "tenant_name = \"vespa-team\"\n",
                "\n",
                "# Key is only used for CI/CD. Can be removed if logging in interactively\n",
                "key = os.getenv(\"VESPA_TEAM_API_KEY\", None)\n",
                "if key is not None:\n",
                "    key = key.replace(r\"\\n\", \"\\n\")  # To parse key correctly\n",
                "\n",
                "vespa_cloud = VespaCloud(\n",
                "    tenant=tenant_name,\n",
                "    application=vespa_app_name,\n",
                "    key_content=key,  # Key is only used for CI/CD. Can be removed if logging in interactively\n",
                "    application_package=vespa_application_package,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc1c140a",
            "metadata": {
                "id": "fa9baa5a"
            },
            "source": [
                "Now deploy the app to Vespa Cloud dev zone.\n",
                "\n",
                "The first deployment typically takes 2 minutes until the endpoint is up.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "494f5144",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 12057,
                    "status": "ok",
                    "timestamp": 1706652033883,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "fe954dc4",
                "outputId": "6150363c-cfac-4240-e790-f84f98c481b0"
            },
            "outputs": [],
            "source": [
                "from vespa.application import Vespa\n",
                "\n",
                "app: Vespa = vespa_cloud.deploy()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "abc3be8f",
            "metadata": {
                "id": "54db44b1"
            },
            "source": [
                "## Feed our sample documents and their binary embedding representation\n",
                "\n",
                "With few documents, we use the synchronous API. Read more in [reads and writes](https://pyvespa.readthedocs.io/en/latest/reads-writes.html).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "00aad720",
            "metadata": {},
            "outputs": [],
            "source": [
                "from vespa.io import VespaResponse\n",
                "\n",
                "with app.syncio(connections=12) as sync:\n",
                "    for i, doc in enumerate(documents):\n",
                "        response: VespaResponse = sync.feed_data_point(\n",
                "            schema=\"doc\",\n",
                "            data_id=str(i),\n",
                "            fields={\n",
                "                \"doc_id\": str(i),\n",
                "                \"text\": doc,\n",
                "                \"binary_vector\": cohere_response.embeddings.binary[i],\n",
                "            },\n",
                "        )\n",
                "        assert response.is_successful()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ed41512b",
            "metadata": {},
            "source": [
                "For some cases where we have lots of vector data, we can use\n",
                "the [hex format for binary indexed tensors](https://docs.vespa.ai/en/reference/document-json-format.html#tensor-hex-dump).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "95b5b710",
            "metadata": {},
            "outputs": [],
            "source": [
                "from binascii import hexlify\n",
                "import numpy as np\n",
                "\n",
                "\n",
                "def to_hex_str(binary_vector):\n",
                "    return str(hexlify(np.array(binary_vector, dtype=np.int8)), \"utf-8\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1bb17438",
            "metadata": {},
            "source": [
                "Feed using hex format\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "88eb5380",
            "metadata": {},
            "outputs": [],
            "source": [
                "with app.syncio() as sync:\n",
                "    for i, doc in enumerate(documents):\n",
                "        response: VespaResponse = sync.feed_data_point(\n",
                "            schema=\"doc\",\n",
                "            data_id=str(i),\n",
                "            fields={\n",
                "                \"doc_id\": str(i),\n",
                "                \"text\": doc,\n",
                "                \"binary_vector\": {\n",
                "                    \"values\": to_hex_str(cohere_response.embeddings.binary[i])\n",
                "                },\n",
                "            },\n",
                "        )\n",
                "        assert response.is_successful()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c39b1f1a",
            "metadata": {
                "id": "20b007ec"
            },
            "source": [
                "### Querying data\n",
                "\n",
                "Read more about querying Vespa in:\n",
                "\n",
                "- [Vespa Query API](https://docs.vespa.ai/en/query-api.html)\n",
                "- [Vespa Query API reference](https://docs.vespa.ai/en/reference/query-api-reference.html)\n",
                "- [Vespa Query Language API (YQL)](https://docs.vespa.ai/en/query-language.html)\n",
                "- [Practical Nearest Neighbor Search Guide](https://docs.vespa.ai/en/nearest-neighbor-search-guide.html)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "377da3d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"Who discovered x-ray?\"\n",
                "\n",
                "# Make sure to set input_type=\"search_query\" when getting the embeddings for the query.\n",
                "# We ask for both float and binary query embeddings\n",
                "cohere_query_response = co.embed(\n",
                "    [query],\n",
                "    model=\"embed-english-v3.0\",\n",
                "    input_type=\"search_query\",\n",
                "    embedding_types=[\"float\", \"binary\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2d086ade",
            "metadata": {},
            "source": [
                "Now, we use nearestNeighbor search to retrieve 100 hits using hamming distance, these hits are then exposed to vespa ranking framework, where we re-rank\n",
                "using the dot product between the float tensor and the unpacked binary vector (the unpack returns a 1024 float version).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "686f1cf0",
            "metadata": {},
            "outputs": [],
            "source": [
                "response = app.query(\n",
                "    yql=\"select * from doc where {targetHits:100}nearestNeighbor(binary_vector,q_binary)\",\n",
                "    ranking=\"rerank\",\n",
                "    body={\n",
                "        \"input.query(q_binary)\": to_hex_str(cohere_query_response.embeddings.binary[0]),\n",
                "        \"input.query(q_full)\": cohere_query_response.embeddings.float[0],\n",
                "    },\n",
                ")\n",
                "assert response.is_successful()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "id": "7f84d4c6",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'id': 'id:doc:doc::3',\n",
                            "  'relevance': 8.697503089904785,\n",
                            "  'source': 'cohere_content',\n",
                            "  'fields': {'matchfeatures': {'closeness(field,binary_vector)': 0.0029940119760479044,\n",
                            "    'distance(field,binary_vector)': 333.0},\n",
                            "   'sddocname': 'doc',\n",
                            "   'documentid': 'id:doc:doc::3',\n",
                            "   'doc_id': '3',\n",
                            "   'text': 'Marie Curie was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity'}},\n",
                            " {'id': 'id:doc:doc::1',\n",
                            "  'relevance': 6.413589954376221,\n",
                            "  'source': 'cohere_content',\n",
                            "  'fields': {'matchfeatures': {'closeness(field,binary_vector)': 0.002551020408163265,\n",
                            "    'distance(field,binary_vector)': 391.00000000000006},\n",
                            "   'sddocname': 'doc',\n",
                            "   'documentid': 'id:doc:doc::1',\n",
                            "   'doc_id': '1',\n",
                            "   'text': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.'}},\n",
                            " {'id': 'id:doc:doc::2',\n",
                            "  'relevance': 6.379772663116455,\n",
                            "  'source': 'cohere_content',\n",
                            "  'fields': {'matchfeatures': {'closeness(field,binary_vector)': 0.002652519893899204,\n",
                            "    'distance(field,binary_vector)': 376.0},\n",
                            "   'sddocname': 'doc',\n",
                            "   'documentid': 'id:doc:doc::2',\n",
                            "   'doc_id': '2',\n",
                            "   'text': 'Isaac Newton was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author who was described in his time as a natural philosopher.'}},\n",
                            " {'id': 'id:doc:doc::0',\n",
                            "  'relevance': 4.5963287353515625,\n",
                            "  'source': 'cohere_content',\n",
                            "  'fields': {'matchfeatures': {'closeness(field,binary_vector)': 0.0024271844660194173,\n",
                            "    'distance(field,binary_vector)': 411.00000000000006},\n",
                            "   'sddocname': 'doc',\n",
                            "   'documentid': 'id:doc:doc::0',\n",
                            "   'doc_id': '0',\n",
                            "   'text': 'Alan Turing  was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.'}}]"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "response.hits"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bb8922bc",
            "metadata": {},
            "source": [
                "Notice the returned hits. The `relevance` is the score assigned by the second-phase dot product between the full query version\n",
                "and the unpacked binary vector. Also, we see the match features and the hamming distances. Notice that the re-ranking step\n",
                "has re-ordered doc 1 and doc 2.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9b9f45d3",
            "metadata": {
                "id": "7c8b8223"
            },
            "source": [
                "## Conclusions\n",
                "\n",
                "These new Cohere binary embeddings are a huge step forward for cost-efficient vector search at scale and integrates perfectly\n",
                "with the rich feature set in Vespa.\n",
                "\n",
                "### Clean up\n",
                "\n",
                "We can now delete the cloud instance:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7fb27b941602401d91542211134fc71a",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 3720,
                    "status": "ok",
                    "timestamp": 1705505103257,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "71e310e3",
                "outputId": "991b1965-6c33-4985-e873-a92c43695528"
            },
            "outputs": [],
            "source": [
                "vespa_cloud.delete()"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "name": "",
            "provenance": [
                {
                    "file_id": "1FoVAybR6dhXy-uDkVuDfBtVzSJoresCB",
                    "timestamp": 1706644027750
                }
            ],
            "version": ""
        },
        "kernelspec": {
            "display_name": "Python 3.11.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "vscode": {
            "interpreter": {
                "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}