{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b861c1fb",
   "metadata": {},
   "source": [
    "![Vespa logo](https://vespa.ai/assets/vespa-logo-color.png)\n",
    "\n",
    "# LightGBM: Mapping model features to Vespa features\n",
    "\n",
    "The main goal of this tutorial is to show how to deploy a LightGBM model with feature names that do not match Vespa feature names.\n",
    "\n",
    "The following tasks will be accomplished throughout the tutorial:\n",
    "\n",
    "1. Train a LightGBM classification model with generic feature names that will not be available in the Vespa application.\n",
    "2. Create an application package and include a mapping from Vespa feature names to LightGBM model feature names.\n",
    "3. Create Vespa application package files and export then to an application folder.\n",
    "4. Export the trained LightGBM model to the Vespa application folder.\n",
    "5. Deploy the Vespa application using the application folder.\n",
    "6. Feed data to the Vespa application.\n",
    "7. Assert that the LightGBM predictions from the deployed model are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a583b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Refer to <a href=\"https://pyvespa.readthedocs.io/en/latest/troubleshooting.html\">troubleshooting</a>\n",
    "    for any problem when running this guide.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b3c78",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013476a6",
   "metadata": {},
   "source": [
    "Install and load required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b74fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas pyvespa lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b098527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537186d1",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e6072",
   "metadata": {},
   "source": [
    "Simulate data that will be used to train the LightGBM model. Note that Vespa does not automatically recognize the feature names `feature_1`, `feature_2` and `feature_3`. When creating the application package we need to map those variables to something that the Vespa application recognizes, such as a document attribute or query value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c12c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811887</td>\n",
       "      <td>0.599438</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781972</td>\n",
       "      <td>0.826391</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.994432</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.753858</td>\n",
       "      <td>0.209207</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295258</td>\n",
       "      <td>0.529206</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2 feature_3\n",
       "0   0.811887   0.599438         a\n",
       "1   0.781972   0.826391         c\n",
       "2   0.954950   0.994432         a\n",
       "3   0.753858   0.209207         a\n",
       "4   0.295258   0.529206         c"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random training set\n",
    "features = pd.DataFrame({\n",
    "            \"feature_1\": np.random.random(100),\n",
    "            \"feature_2\": np.random.random(100),\n",
    "            \"feature_3\": pd.Series(np.random.choice([\"a\", \"b\", \"c\"], size=100), dtype=\"category\")\n",
    "    \n",
    "        })\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb11b72",
   "metadata": {},
   "source": [
    "Create a target variable that depends on `feature_1`, `feature_2` and `feature_3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350e8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     1.0\n",
       "2     1.0\n",
       "3     0.0\n",
       "4     1.0\n",
       "     ... \n",
       "95    0.0\n",
       "96    0.0\n",
       "97    0.0\n",
       "98    1.0\n",
       "99    1.0\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = pd.get_dummies(features)\n",
    "targets = (\n",
    "    (numeric_features[\"feature_1\"] + \n",
    "     numeric_features[\"feature_2\"]  -\n",
    "     0.5 * numeric_features[\"feature_3_a\"] + \n",
    "     0.5 * numeric_features[\"feature_3_c\"]) > 1.0\n",
    ") * 1.0\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656c30b",
   "metadata": {},
   "source": [
    "## Fit lightgbm model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf94ff8",
   "metadata": {},
   "source": [
    "Train the LightGBM model on the simulated data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 55, number of negative: 45\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 74\n",
      "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550000 -> initscore=0.200671\n",
      "[LightGBM] [Info] Start training from score 0.200671\n"
     ]
    }
   ],
   "source": [
    "training_set = lgb.Dataset(features, targets)\n",
    "\n",
    "# Train the model\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 3,\n",
    "}\n",
    "model = lgb.train(params, training_set, num_boost_round=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ad684",
   "metadata": {},
   "source": [
    "## Vespa application package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d2d11",
   "metadata": {},
   "source": [
    "Create the application package and map the LightGBM feature names to the related Vespa names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41787c17",
   "metadata": {},
   "source": [
    "In this example we are going to assume that `feature_1` represents the document field `numeric` and map `feature_1` to `attribute(numeric)` through the use of a Vespa `Function` in the corresponding `RankProfile`. `feature_2` maps to a `value` that will be sent along with the query, and this is represented in Vespa by mapping `query(value)` to `feature_2`. Lastly, the categorical feature is mapped from `attribute(categorical)` to `feature_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458b6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage, Field, RankProfile, Function\n",
    "\n",
    "app_package = ApplicationPackage(name=\"lightgbm\")\n",
    "app_package.schema.add_fields(\n",
    "    Field(name=\"id\", type=\"string\", indexing=[\"summary\", \"attribute\"]),   \n",
    "    Field(name=\"numeric\", type=\"double\", indexing=[\"summary\", \"attribute\"]),\n",
    "    Field(name=\"categorical\", type=\"string\", indexing=[\"summary\", \"attribute\"])\n",
    ")\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"classify\", \n",
    "        functions=[\n",
    "            Function(name=\"feature_1\", expression=\"attribute(numeric)\"),\n",
    "            Function(name=\"feature_2\", expression=\"query(value)\"),\n",
    "            Function(name=\"feature_3\", expression=\"attribute(categorical)\")            \n",
    "            \n",
    "        ],\n",
    "        first_phase=\"lightgbm('lightgbm_model.json')\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2850fa2",
   "metadata": {},
   "source": [
    "We can check how the Vespa search defition file will look like. Note that `feature_1`, `feature_2` and `feature_3` required by the LightGBM model are now defined on the schema definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b129451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema lightgbm {\n",
      "    document lightgbm {\n",
      "        field id type string {\n",
      "            indexing: summary | attribute\n",
      "        }\n",
      "        field numeric type double {\n",
      "            indexing: summary | attribute\n",
      "        }\n",
      "        field categorical type string {\n",
      "            indexing: summary | attribute\n",
      "        }\n",
      "    }\n",
      "    rank-profile classify {\n",
      "        function feature_1() {\n",
      "            expression {\n",
      "                attribute(numeric)\n",
      "            }\n",
      "        }\n",
      "        function feature_2() {\n",
      "            expression {\n",
      "                query(value)\n",
      "            }\n",
      "        }\n",
      "        function feature_3() {\n",
      "            expression {\n",
      "                attribute(categorical)\n",
      "            }\n",
      "        }\n",
      "        first-phase {\n",
      "            expression: lightgbm('lightgbm_model.json')\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(app_package.schema.schema_to_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc65f6",
   "metadata": {},
   "source": [
    "We can export the application package files to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49bba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"lightgbm\").mkdir(parents=True, exist_ok=True)\n",
    "app_package.to_files(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2a034",
   "metadata": {},
   "source": [
    "Note that we don't have any models under the `models` folder. We need to export the lightGBM model that we trained earlier to `models/lightgbm.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b00a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mlightgbm\u001b[00m\r\n",
      "├── \u001b[01;34mfiles\u001b[00m\r\n",
      "├── \u001b[01;34mmodels\u001b[00m\r\n",
      "│   └── lightgbm_model.json\r\n",
      "├── \u001b[01;34mschemas\u001b[00m\r\n",
      "│   └── lightgbm.sd\r\n",
      "├── \u001b[01;34msearch\u001b[00m\r\n",
      "│   └── \u001b[01;34mquery-profiles\u001b[00m\r\n",
      "│       ├── default.xml\r\n",
      "│       └── \u001b[01;34mtypes\u001b[00m\r\n",
      "│           └── root.xml\r\n",
      "└── services.xml\r\n",
      "\r\n",
      "6 directories, 5 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb737c",
   "metadata": {},
   "source": [
    "## Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1800f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lightgbm/models/lightgbm_model.json\", \"w\") as f:\n",
    "    json.dump(model.dump_model(), f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3563968",
   "metadata": {},
   "source": [
    "Now we can see that the model is where Vespa expects it to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c4a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mlightgbm\u001b[00m\r\n",
      "├── \u001b[01;34mfiles\u001b[00m\r\n",
      "├── \u001b[01;34mmodels\u001b[00m\r\n",
      "│   └── lightgbm_model.json\r\n",
      "├── \u001b[01;34mschemas\u001b[00m\r\n",
      "│   └── lightgbm.sd\r\n",
      "├── \u001b[01;34msearch\u001b[00m\r\n",
      "│   └── \u001b[01;34mquery-profiles\u001b[00m\r\n",
      "│       ├── default.xml\r\n",
      "│       └── \u001b[01;34mtypes\u001b[00m\r\n",
      "│           └── root.xml\r\n",
      "└── services.xml\r\n",
      "\r\n",
      "6 directories, 5 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04cc80",
   "metadata": {},
   "source": [
    "## Deploy the application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d61784",
   "metadata": {},
   "source": [
    "Deploy the application package from disk with Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b754666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Waiting for configuration server, 10/300 seconds...\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Waiting for application status, 10/300 seconds...\n",
      "Waiting for application status, 15/300 seconds...\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy_from_disk(application_name=\"lightgbm\", application_root=\"lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43993b02",
   "metadata": {},
   "source": [
    "## Feed the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5587be",
   "metadata": {},
   "source": [
    "Feed the simulated data. To feed data in batch we need to create a list of dictionaries containing id and fields keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49283cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_batch = [\n",
    "    {\n",
    "        \"id\": idx, \n",
    "        \"fields\": {\"id\": idx,\n",
    "                   \"numeric\": row[\"feature_1\"],\n",
    "                   \"categorical\": row[\"feature_3\"]}\n",
    "    } for idx, row in features.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81915a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful documents fed: 100/100.\n",
      "Batch progress: 1/1.\n"
     ]
    }
   ],
   "source": [
    "from vespa.io import VespaResponse \n",
    "\n",
    "def callback(response:VespaResponse, id:str):\n",
    "    if not response.is_successfull():\n",
    "        print(f\"Document {id} was not fed to Vespa due to error: {response.get_json()}\")\n",
    "   \n",
    "app.feed_iterable(feed_batch, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fcd6b",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b309e39",
   "metadata": {},
   "source": [
    "Predict with the trained LightGBM model so that we can later compare with the predictions returned by Vespa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c75a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"model_prediction\"] = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de678f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811887</td>\n",
       "      <td>0.599438</td>\n",
       "      <td>a</td>\n",
       "      <td>0.450747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781972</td>\n",
       "      <td>0.826391</td>\n",
       "      <td>c</td>\n",
       "      <td>0.711523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.994432</td>\n",
       "      <td>a</td>\n",
       "      <td>0.522019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.753858</td>\n",
       "      <td>0.209207</td>\n",
       "      <td>a</td>\n",
       "      <td>0.450747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295258</td>\n",
       "      <td>0.529206</td>\n",
       "      <td>c</td>\n",
       "      <td>0.688877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.906236</td>\n",
       "      <td>0.547653</td>\n",
       "      <td>a</td>\n",
       "      <td>0.450747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.474415</td>\n",
       "      <td>0.483834</td>\n",
       "      <td>a</td>\n",
       "      <td>0.450747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.041351</td>\n",
       "      <td>0.459862</td>\n",
       "      <td>b</td>\n",
       "      <td>0.397582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.402415</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>c</td>\n",
       "      <td>0.711523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.692193</td>\n",
       "      <td>0.537700</td>\n",
       "      <td>c</td>\n",
       "      <td>0.688877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_1  feature_2 feature_3  model_prediction\n",
       "0    0.811887   0.599438         a          0.450747\n",
       "1    0.781972   0.826391         c          0.711523\n",
       "2    0.954950   0.994432         a          0.522019\n",
       "3    0.753858   0.209207         a          0.450747\n",
       "4    0.295258   0.529206         c          0.688877\n",
       "..        ...        ...       ...               ...\n",
       "95   0.906236   0.547653         a          0.450747\n",
       "96   0.474415   0.483834         a          0.450747\n",
       "97   0.041351   0.459862         b          0.397582\n",
       "98   0.402415   0.831825         c          0.711523\n",
       "99   0.692193   0.537700         c          0.688877\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7746e2b",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75f4bb",
   "metadata": {},
   "source": [
    "Create a `compute_vespa_relevance` function that takes a document `id` and a query `value` and return the LightGBM model deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b32c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4507470801266155"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_vespa_relevance(id_value:int):\n",
    "    hits = app.query(\n",
    "        body={\n",
    "            \"yql\": \"select * from sources * where id = {}\".format(str(id_value)),\n",
    "            \"ranking\": \"classify\",\n",
    "            \"ranking.features.query(value)\": features.loc[id_value, \"feature_2\"],\n",
    "            \"hits\": 1\n",
    "        }\n",
    "    ).hits\n",
    "    return hits[0][\"relevance\"]\n",
    "\n",
    "compute_vespa_relevance(id_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddc138",
   "metadata": {},
   "source": [
    "Loop through the `features` to compute a vespa prediction for all the data points, so that we can compare it to the predictions made by the model outside Vespa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vespa_relevance = []\n",
    "for idx, row in features.iterrows():\n",
    "    vespa_relevance.append(compute_vespa_relevance(id_value=idx))\n",
    "features[\"vespa_relevance\"] = vespa_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad8e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>model_prediction</th>\n",
       "      <th>vespa_relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811887</td>\n",
       "      <td>0.599438</td>\n",
       "      <td>a</td>\n",
       "      <td>0.450747</td>\n",
       "      <td>0.450747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781972</td>\n",
       "      <td>0.826391</td>\n",
       "      <td>c</td>\n",
       "      <td>0.711523</td>\n",
       "      <td>0.711523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.994432</td>\n",
       "      <td>a</td>\n",
       "      <td>0.522019</td>\n",
       "      <td>0.522019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.753858</td>\n",
       "      <td>0.209207</td>\n",
       "      <td>a</td>\n",
       "      <td>0.450747</td>\n",
       "      <td>0.450747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295258</td>\n",
       "      <td>0.529206</td>\n",
       "      <td>c</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.688877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.906236</td>\n",
       "      <td>0.547653</td>\n",
       "      <td>a</td>\n",
       "      <td>0.450747</td>\n",
       "      <td>0.450747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.474415</td>\n",
       "      <td>0.483834</td>\n",
       "      <td>a</td>\n",
       "      <td>0.450747</td>\n",
       "      <td>0.450747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.041351</td>\n",
       "      <td>0.459862</td>\n",
       "      <td>b</td>\n",
       "      <td>0.397582</td>\n",
       "      <td>0.397582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.402415</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>c</td>\n",
       "      <td>0.711523</td>\n",
       "      <td>0.711523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.692193</td>\n",
       "      <td>0.537700</td>\n",
       "      <td>c</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.688877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_1  feature_2 feature_3  model_prediction  vespa_relevance\n",
       "0    0.811887   0.599438         a          0.450747         0.450747\n",
       "1    0.781972   0.826391         c          0.711523         0.711523\n",
       "2    0.954950   0.994432         a          0.522019         0.522019\n",
       "3    0.753858   0.209207         a          0.450747         0.450747\n",
       "4    0.295258   0.529206         c          0.688877         0.688877\n",
       "..        ...        ...       ...               ...              ...\n",
       "95   0.906236   0.547653         a          0.450747         0.450747\n",
       "96   0.474415   0.483834         a          0.450747         0.450747\n",
       "97   0.041351   0.459862         b          0.397582         0.397582\n",
       "98   0.402415   0.831825         c          0.711523         0.711523\n",
       "99   0.692193   0.537700         c          0.688877         0.688877\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d14754",
   "metadata": {},
   "source": [
    "## Compare model and Vespa predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01525f7e",
   "metadata": {},
   "source": [
    "Predictions from the model should be equal to predictions from Vespa, showing the model was correctly deployed to Vespa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a194862",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert features[\"model_prediction\"].tolist() == features[\"vespa_relevance\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f15b18",
   "metadata": {},
   "source": [
    "## Clean environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c40135",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr lightgbm\n",
    "vespa_docker.container.stop()\n",
    "vespa_docker.container.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
