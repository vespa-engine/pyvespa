{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ae8a2b",
   "metadata": {},
   "source": [
    "![Vespa Cloud logo](https://cloud.vespa.ai/assets/logos/vespa-cloud-logo-full-black.png)\n",
    "\n",
    "\n",
    "# Building cost-efficient retrieval-augmented personal AI assistants\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use [Vespa streaming mode](https://docs.vespa.ai/en/streaming-search.html) for cost-efficient retrieval for applications that \n",
    "store and retrieve personal data. You can read more about Vespa vector streaming search in these two blog posts:\n",
    "\n",
    "\n",
    "- [Yahoo Mail turns to Vespa to do RAG at scale](https://blog.vespa.ai/yahoo-mail-turns-to-vespa-to-do-rag-at-scale/)\n",
    "- [Announcing vector streaming search: AI assistants at scale without breaking the bank](https://blog.vespa.ai/announcing-vector-streaming-search/)\n",
    "\n",
    "\n",
    "This notebook demonstrates how to build a¬†[LlamaIndex](https://gpt-index.readthedocs.io/en/latest/)\n",
    "[Retriever](https://gpt-index.readthedocs.io/en/latest/core_modules/query_modules/retriever/root.html) that can \n",
    "retrieve data from a [Vespa](https://vespa.ai/) deployment using streaming mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyvespa llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be72e92e",
   "metadata": {},
   "source": [
    "## Synthetic Mail Sample Data \n",
    "There are few public email datasets because people care about their privacy,  so this notebook uses synthetic data to examine how to use Vespa streaming search. \n",
    "We create a generator function yields a `dict` with synthetic mail data. Notice that the dict has three keys:\n",
    "\n",
    "- `id`\n",
    "- `groupname`\n",
    "- `fields` \n",
    "\n",
    "This is the expected feed format for [PyVespa](https://pyvespa.readthedocs.io/en/latest/reads-writes.html) feed operations and\n",
    "where PyVespa will use these to build a Vespa [document v1 api](https://docs.vespa.ai/en/document-v1-api-guide.html) request(s). The groupname is only required when using\n",
    "streaming mode.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76a69972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def synthetic_mail_data_generator() -> List[dict]:\n",
    "    synthetic_mails = [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"groupname\": \"bergum@vespa.ai\",\n",
    "            \"fields\": {\n",
    "                \"subject\": \"LlamaIndex news, 2023-11-14\",\n",
    "                \"to\": \"bergum@vespa.ai\",\n",
    "                \"body\": \"\"\"Hello Llama Friends ü¶ô LlamaIndex is 1 year old this week! üéâ To celebrate, we're taking a stroll down memory \n",
    "                    lane on our blog with twelve milestones from our first year. Be sure to check it out.\"\"\",\n",
    "                \"from\": \"news@llamaindex.ai\",\n",
    "                \"display_date\": \"2023-11-15T09:00:00Z\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"groupname\": \"bergum@vespa.ai\",\n",
    "            \"fields\": {\n",
    "                \"subject\": \"Dentist Appointment Reminder\",\n",
    "                \"to\": \"bergum@vespa.ai\",\n",
    "                \"body\": \"Dear Jo Kristian ,\\nThis is a reminder for your upcoming dentist appointment on 2023-12-04 at 09:30. Please arrive 15 minutes early.\\nBest regards,\\nDr. Dentist\",\n",
    "                \"from\": \"dentist@dentist.no\",\n",
    "                \"display_date\": \"2023-11-20T15:30:00Z\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"groupname\": \"giraffe@wildlife.ai\",\n",
    "            \"fields\": {\n",
    "                \"subject\": \"Wildlife Update: Giraffe Edition\",\n",
    "                \"to\": \"giraffe@wildlife.ai\",\n",
    "                \"body\": \"Dear Wildlife Enthusiasts ü¶í, We're thrilled to share the latest insights into giraffe behavior in the wild. Join us on an adventure as we explore their natural habitat and learn more about these majestic creatures.\",\n",
    "                \"from\": \"updates@wildlife.ai\",\n",
    "                \"display_date\": \"2023-11-20T14:30:00Z\"\n",
    "        }\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"groupname\": \"penguin@antarctica.ai\",\n",
    "            \"fields\": {\n",
    "                \"subject\": \"Antarctica Expedition: Penguin Chronicles\",\n",
    "                \"to\": \"penguin@antarctica.ai\",\n",
    "                \"body\": \"Greetings Explorers üêß, Our team is embarking on an exciting expedition to Antarctica to study penguin colonies. Stay tuned for live updates and behind-the-scenes footage as we dive into the world of these fascinating birds.\",\n",
    "                \"from\": \"expedition@antarctica.ai\",\n",
    "                \"display_date\": \"2023-11-25T11:45:00Z\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"groupname\": \"space@exploration.ai\",\n",
    "            \"fields\": {\n",
    "                \"subject\": \"Space Exploration News: November Edition\",\n",
    "                \"to\": \"space@exploration.ai\",\n",
    "                \"body\": \"Hello Space Enthusiasts üöÄ, Join us as we highlight the latest discoveries and breakthroughs in space exploration. From distant galaxies to new technologies, there's a lot to explore!\",\n",
    "                \"from\": \"news@exploration.ai\",\n",
    "                \"display_date\": \"2023-11-30T16:20:00Z\"\n",
    "            }\n",
    "         },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"groupname\": \"ocean@discovery.ai\",\n",
    "            \"fields\": {\n",
    "                \"subject\": \"Ocean Discovery: Hidden Treasures Unveiled\",\n",
    "                \"to\": \"ocean@discovery.ai\",\n",
    "                \"body\": \"Dear Ocean Explorers üåä, Dive deep into the secrets of the ocean with our latest discoveries. From undiscovered species to underwater landscapes, our team is uncovering the wonders of the deep blue.\",\n",
    "                \"from\": \"discovery@ocean.ai\",\n",
    "                \"display_date\": \"2023-12-05T10:15:00Z\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    for mail in synthetic_mails:\n",
    "        yield mail  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da356d25",
   "metadata": {},
   "source": [
    "## Definining a Vespa application\n",
    "[PyVespa](https://pyvespa.readthedocs.io/en/latest/) can help us build the [Vespa application package](https://docs.vespa.ai/en/application-packages.html) which is\n",
    "a set of configuration files that defines a Vespa application.  \n",
    "\n",
    "First, we define a [Vespa schema](https://docs.vespa.ai/en/schemas.html). [PyVespa](https://pyvespa.readthedocs.io/en/latest/)\n",
    "offers a programatic api for creating the schema. In the end it is serialized to a file (`<schema>.sd`) before it can be deployed to Vespa. \n",
    "\n",
    "Vespa is statically typed, so we need to define the fields and their type in the schema. \n",
    "Note that we set `mode` to `streaming` which enables [Vespa streaming mode for this schema](https://docs.vespa.ai/en/streaming-search.html). \n",
    "Other valid modes are `indexed` and `store-only`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dca2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from vespa.package import Schema, Document, Field, FieldSet, HNSW\n",
    "mail_schema = Schema(\n",
    "            name=\"mail\",\n",
    "            mode=\"streaming\",\n",
    "            document=Document(\n",
    "                fields=[\n",
    "                    Field(name=\"id\", type=\"string\", indexing=[\"summary\", \"index\"]),\n",
    "                    Field(name=\"subject\", type=\"string\", indexing=[\"index\", \"summary\"]),\n",
    "                    Field(name=\"to\", type=\"string\", indexing=[\"index\", \"summary\"]),\n",
    "                    Field(name=\"from\", type=\"string\", indexing=[\"index\", \"summary\"]),\n",
    "                    Field(name=\"body\", type=\"string\", indexing=[\"index\", \"summary\"]),\n",
    "                    Field(name=\"display_date\", type=\"string\", indexing=[\"summary\"]),\n",
    "                    Field(name=\"timestamp\", type=\"long\", indexing=[\"input display_date\", \"to_epoch_second\", \"summary\", \"attribute\"], is_document_field=False),\n",
    "                    Field(name=\"embedding\", type=\"tensor<bfloat16>(x[384])\",\n",
    "                        indexing=[\"\\\"passage: \\\" . input subject .\\\" \\\". input body\", \"embed e5\", \"attribute\", \"index\"],\n",
    "                        ann=HNSW(distance_metric=\"angular\"),\n",
    "                        is_document_field=False\n",
    "                    )\n",
    "                ],\n",
    "            ),\n",
    "            fieldsets=[\n",
    "                FieldSet(name = \"default\", fields = [\"subject\", \"body\", \"to\", \"from\"])\n",
    "            ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834fe25",
   "metadata": {},
   "source": [
    "In the `mail` schema, we have six document fields; these are provided by us when we feed documents of type `mail` to this app. \n",
    "\n",
    "In addition there are two synthetic fields `timestamp` and `embedding` that uses Vespa [indexing expressions](https://docs.vespa.ai/en/reference/indexing-language-reference.html)\n",
    "taking inputs from the document. \n",
    "\n",
    "- the `timestamp` field takes the input `display_date` and use [converter](https://docs.vespa.ai/en/reference/indexing-language-reference.html#converter) to convert the \n",
    "display date into an epoch timestamp.\n",
    "- the `embedding` tensor field takes the subject and body as input and feeds that into an [embed](https://docs.vespa.ai/en/embedding.html#embedding-a-document-field) function\n",
    "that uses an embedding model to map the string input into an embedding vector representation using 384 dimensions using `bfloat16` precision. Vectors\n",
    "in Vespa are represented as [Tensors](https://docs.vespa.ai/en/tensor-user-guide.html). \n",
    "\n",
    "Now, for the observant reader, you might have noticed the `e5` argument to the `embed` expression in the above `embedding` field. \n",
    "This references a component of the type [hugging-face-embedder](https://docs.vespa.ai/en/embedding.html#huggingface-embedder). Now, we configure\n",
    "the application package and its name, with the schema previously defined and the `e5` embedder component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66c5da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage, Component, Parameter\n",
    "\n",
    "vespa_app_name = \"assistant\"\n",
    "vespa_application_package = ApplicationPackage(\n",
    "        name=vespa_app_name,\n",
    "        schema=[mail_schema],\n",
    "        components=[Component(id=\"e5\", type=\"hugging-face-embedder\",\n",
    "            parameters=[\n",
    "                Parameter(\"transformer-model\", {\"url\": \"https://github.com/vespa-engine/sample-apps/raw/master/simple-semantic-search/model/e5-small-v2-int8.onnx\"}),\n",
    "                Parameter(\"tokenizer-model\", {\"url\": \"https://raw.githubusercontent.com/vespa-engine/sample-apps/master/simple-semantic-search/model/tokenizer.json\"})\n",
    "            ]\n",
    "        )]\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3d7bd",
   "metadata": {},
   "source": [
    "In the last step we configure [ranking](https://docs.vespa.ai/en/ranking.html) by adding `rank-profile`'s to the mail schema. Vespa \n",
    "supports [phased ranking](https://docs.vespa.ai/en/phased-ranking.html) and has a rich set of built-in [rank-features](https://docs.vespa.ai/en/reference/rank-features.html)\n",
    "and users can also define custom functions with [ranking expressions](https://docs.vespa.ai/en/reference/ranking-expressions.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8ce5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import RankProfile, Function\n",
    "\n",
    "keywords = RankProfile(\n",
    "    name=\"default\", \n",
    "    functions=[Function(\n",
    "        name=\"my_function\", expression=\"nativeRank(subject) + nativeRank(body) + freshness(timestamp)\"\n",
    "    )],\n",
    "    first_phase=\"my_function\",\n",
    "    match_features=[\"nativeRank(subject)\", \"nativeRank(body)\", \"my_function\", \"freshness(timestamp)\"],\n",
    ")\n",
    "\n",
    "semantic = RankProfile(\n",
    "    name=\"semantic\", \n",
    "    functions=[Function(\n",
    "        name=\"cosine\", expression=\"max(0,cos(distance(field, embedding)))\"\n",
    "    )],\n",
    "    inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "    first_phase=\"cosine\",\n",
    "    match_features=[\"cosine\", \"freshness(timestamp)\", \"distance(field, embedding)\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "408d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_schema.add_rank_profile(keywords)\n",
    "mail_schema.add_rank_profile(semantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79833205",
   "metadata": {},
   "source": [
    "Now, we have our basic Vespa schema and application package, we can serialize the representation to application package files. \n",
    "This is handy when we want to start working with production deployments and version control. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed430761",
   "metadata": {},
   "outputs": [],
   "source": [
    "vespa_application_package.to_files(\"app-directory\")\n",
    "import os\n",
    "\n",
    "def print_files_in_directory(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))\n",
    "print_files_in_directory(\"saved-app-directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846545f9",
   "metadata": {},
   "source": [
    "## Deploy the application to Vespa Cloud\n",
    "\n",
    "With the basic application ready, we can deploy it to [Vespa Cloud](https://cloud.vespa.ai/en/). \n",
    "It's also possible to deploy the app using docker, \n",
    "see [Hybrid Search - Quickstart](https://pyvespa.readthedocs.io/en/latest/getting-started-pyvespa.html) for\n",
    "a complete example of how to deploy the app to a local docker container. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16179d9b",
   "metadata": {},
   "source": [
    "Install the Vespa CLI using [homebrew](https://brew.sh/) - or download a binary from GitHub as demonstrated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343981ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew install vespa-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d0700",
   "metadata": {},
   "source": [
    "Alternatively, if running in Colab, download the Vespa CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5670bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "res = requests.get(url=\"https://api.github.com/repos/vespa-engine/vespa/releases/latest\").json()\n",
    "os.environ[\"VERSION\"] = res[\"tag_name\"].replace(\"v\", \"\")\n",
    "!curl -fsSL https://github.com/vespa-engine/vespa/releases/download/v${VERSION}/vespa-cli_${VERSION}_linux_amd64.tar.gz | tar -zxf -\n",
    "!ln -sf /content/vespa-cli_${VERSION}_linux_amd64/bin/vespa /bin/vespa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff00727",
   "metadata": {},
   "source": [
    "To deploy the application to Vespa Cloud we need to create a tenant in the Vespa Cloud:\n",
    "\n",
    "Create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/) (unless you already have one). \n",
    "This step requires a Google or GitHub account, and will start your [free trial](https://cloud.vespa.ai/en/free-trial). \n",
    "Make note of the tenant name, it is used in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f9a1c",
   "metadata": {},
   "source": [
    "### Configure Vespa Cloud date-plane security\n",
    "\n",
    "Create Vespa Cloud data-plane mTLS cert/key-pair. The mutual certificate pair is used to talk to your Vespa cloud endpoints. See [Vespa Cloud Security Guide](https://cloud.vespa.ai/en/security/guide) for details.\n",
    "\n",
    "We save the paths to the credentials, for later data-plane access without using pyvespa APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a766d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TENANT_NAME\"] = \"vespa-team\" # Replace with your tenant name\n",
    "\n",
    "vespa_cli_command = f'vespa config set application {os.environ[\"TENANT_NAME\"]}.{vespa_app_name}'\n",
    "\n",
    "!vespa config set target cloud\n",
    "!{vespa_cli_command}\n",
    "!vespa auth cert -N "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228381b",
   "metadata": {},
   "source": [
    "Validate that we have the expected data-plane credential files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f0b97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from pathlib import Path\n",
    "\n",
    "cert_path = Path.home() / \".vespa\" / f\"{os.environ['TENANT_NAME']}.{vespa_app_name}.default/data-plane-public-cert.pem\"\n",
    "key_path = Path.home() / \".vespa\" / f\"{os.environ['TENANT_NAME']}.{vespa_app_name}.default/data-plane-private-key.pem\"\n",
    "\n",
    "if not exists(cert_path) or not exists(key_path):\n",
    "    print(\"ERROR: set the correct paths to security credentials. Correct paths above and rerun until you do not see this error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ce80e0",
   "metadata": {},
   "source": [
    "Note that the subsequent Vespa Cloud deploy call below will add `data-plane-public-cert.pem` to the application before deploying it to Vespa Cloud, so that\n",
    "you have access to both the private key and the public certificate, while Vespa Cloud only knows the public certificate. \n",
    "\n",
    "### Configure control-plane security \n",
    "\n",
    "Authenticate to generate a tenant level control plane API key for deploying the applications to Vespa Cloud, and save the path to it. \n",
    "\n",
    "The generated tenant api key must be added in the Vespa Console before attemting to deploy the application. \n",
    "\n",
    "```\n",
    "To use this key in Vespa Cloud click 'Add custom key' at\n",
    "https://console.vespa-cloud.com/tenant/TENANT_NAME/account/keys\n",
    "and paste the entire public key including the BEGIN and END lines.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vespa auth api-key\n",
    "\n",
    "from pathlib import Path\n",
    "api_key_path = Path.home() / \".vespa\" / f\"{os.environ['TENANT_NAME']}.api-key.pem\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db1010",
   "metadata": {},
   "source": [
    "### Deploy to Vespa\n",
    "\n",
    "Now that we have data-plane and control-plane credentials ready, we can deploy our application to Vespa Cloud! `PyVespa` supports deploying to the \n",
    "[development zone](https://cloud.vespa.ai/en/reference/environments#dev-and-perf).\n",
    "\n",
    ">Note: Deployments to dev and perf expire after 7 days of inactivity, i.e., 7 days after running deploy. This applies to all plans, not only the Free Trial. Use the Vespa Console to extend the expiry period, or redeploy the application to add 7 more days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-adoption",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Vespa Cloud logo](https://cloud.vespa.ai/assets/logos/vespa-cloud-logo-full-black.png)\n",
    "\n",
    "# Hybrid Search - Quickstart on Vespa Cloud\n",
    "\n",
    "This is the same guide as [getting-started-pyvespa](https://pyvespa.readthedocs.io/en/latest/getting-started-pyvespa.html), deploying to Vespa Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5fddf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.deployment import VespaCloud\n",
    "\n",
    "def read_secret():\n",
    "    \"\"\"Read the API key from the environment variable. This is \n",
    "    only used for CI/CD purposes.\"\"\"\n",
    "    t = os.getenv(\"VESPA_TEAM_API_KEY\")\n",
    "    if t:\n",
    "        return t.replace(r\"\\n\", \"\\n\")\n",
    "    else:\n",
    "        return t\n",
    "\n",
    "vespa_cloud = VespaCloud(\n",
    "    tenant=os.environ[\"TENANT_NAME\"],\n",
    "    application=vespa_app_name,\n",
    "    key_content=read_secret() if read_secret() else None,\n",
    "    key_location=api_key_path,\n",
    "    application_package=vespa_application_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9baa5a",
   "metadata": {},
   "source": [
    "Now deploy the app to Vespa Cloud dev zone! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe954dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment started in run 4 of dev-aws-us-east-1c for samples.assistant. This may take about 15 minutes the first time.\n",
      "INFO    [17:55:28]  Deploying platform version 8.259.15 and application dev build 4 for dev-aws-us-east-1c of default ...\n",
      "INFO    [17:55:28]  Using CA signed certificate version 0\n",
      "INFO    [17:55:29]  Using 1 nodes in container cluster 'assistant_container'\n",
      "WARNING [17:55:29]  For streaming search cluster 'assistant_content.mail', SD field 'embedding': hnsw index is not relevant and not supported, ignoring setting\n",
      "WARNING [17:55:29]  For streaming search cluster 'assistant_content.mail', SD field 'embedding': hnsw index is not relevant and not supported, ignoring setting\n",
      "INFO    [17:55:30]  Deployment successful.\n",
      "INFO    [17:55:30]  Session 2758 for tenant 'samples' prepared and activated.\n",
      "INFO    [17:55:31]  ######## Details for all nodes ########\n",
      "INFO    [17:55:31]  h88962b.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [17:55:31]  --- platform vespa/cloud-tenant-rhel8:8.259.15\n",
      "INFO    [17:55:31]  --- storagenode on port 19102 has config generation 2758, wanted is 2758\n",
      "INFO    [17:55:31]  --- searchnode on port 19107 has config generation 2758, wanted is 2758\n",
      "INFO    [17:55:31]  --- distributor on port 19111 has config generation 2757, wanted is 2758\n",
      "INFO    [17:55:31]  --- metricsproxy-container on port 19092 has config generation 2758, wanted is 2758\n",
      "INFO    [17:55:31]  h88969f.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [17:55:31]  --- platform vespa/cloud-tenant-rhel8:8.259.15\n",
      "INFO    [17:55:31]  --- container-clustercontroller on port 19050 has config generation 2757, wanted is 2758\n",
      "INFO    [17:55:31]  --- metricsproxy-container on port 19092 has config generation 2757, wanted is 2758\n",
      "INFO    [17:55:31]  h88978a.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [17:55:31]  --- platform vespa/cloud-tenant-rhel8:8.259.15\n",
      "INFO    [17:55:31]  --- logserver-container on port 4080 has config generation 2758, wanted is 2758\n",
      "INFO    [17:55:31]  --- metricsproxy-container on port 19092 has config generation 2757, wanted is 2758\n",
      "INFO    [17:55:31]  h89128a.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [17:55:31]  --- platform vespa/cloud-tenant-rhel8:8.259.15\n",
      "INFO    [17:55:31]  --- container on port 4080 has config generation 2757, wanted is 2758\n",
      "INFO    [17:55:31]  --- metricsproxy-container on port 19092 has config generation 2757, wanted is 2758\n",
      "INFO    [17:55:51]  Found endpoints:\n",
      "INFO    [17:55:51]  - dev.aws-us-east-1c\n",
      "INFO    [17:55:51]   |-- https://e09d41ab.cae25ac9.z.vespa-app.cloud/ (cluster 'assistant_container')\n",
      "INFO    [17:55:51]  Installation succeeded!\n",
      "Using mTLS (key,cert) Authentication against endpoint https://e09d41ab.cae25ac9.z.vespa-app.cloud//ApplicationStatus\n",
      "Application is up!\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.application import Vespa\n",
    "app:Vespa = vespa_cloud.deploy(disk_folder=\"saved-app-directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02430fe9",
   "metadata": {},
   "source": [
    "### Feeding data\n",
    "\n",
    "With the app up and running in Vespa Cloud we can interact with the app, feeding and querying our data. In this case\n",
    "we use the [feed_iterable](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.application.Vespa.feed_iterable) api\n",
    "with a custom `callback` which prints the output of the operation. \n",
    "\n",
    "We pass the `synthetic_mail_data_generator()` and the `schema` and `namespace`. The namespace can be any string, but schema must \n",
    "in our case be `mail` as that is the only schema that is deployed with the app. Read more in [Vespa document ids](https://docs.vespa.ai/en/documents.html#id-scheme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47688f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 fed successfully https://e09d41ab.cae25ac9.z.vespa-app.cloud//document/v1/assistant/mail/group/bergum@vespa.ai/1\n",
      "Document 2 fed successfully https://e09d41ab.cae25ac9.z.vespa-app.cloud//document/v1/assistant/mail/group/bergum@vespa.ai/2\n",
      "Document 1 fed successfully https://e09d41ab.cae25ac9.z.vespa-app.cloud//document/v1/assistant/mail/group/giraffe@wildlife.ai/1\n",
      "Document 1 fed successfully https://e09d41ab.cae25ac9.z.vespa-app.cloud//document/v1/assistant/mail/group/penguin@antarctica.ai/1\n",
      "Document 1 fed successfully https://e09d41ab.cae25ac9.z.vespa-app.cloud//document/v1/assistant/mail/group/space@exploration.ai/1\n",
      "Document 1 fed successfully https://e09d41ab.cae25ac9.z.vespa-app.cloud//document/v1/assistant/mail/group/ocean@discovery.ai/1\n"
     ]
    }
   ],
   "source": [
    "from vespa.io import VespaResponse, VespaQueryResponse\n",
    "\n",
    "def callback(response:VespaResponse, id:str):\n",
    "    if not response.is_successful():\n",
    "        print(f\"Error when feeding document {id}: {response.get_json()}\")\n",
    "    else:\n",
    "        print(f\"Document {id} fed successfully \" + response.url)\n",
    "\n",
    "app.feed_iterable(synthetic_mail_data_generator(), schema=\"mail\", namespace=\"assistant\", callback=callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec21475",
   "metadata": {},
   "source": [
    "PyVespa uses the [document v1 api](https://docs.vespa.ai/en/reference/document-v1-api-reference.html) and the above callback prints the\n",
    "document v1 url. \n",
    "\n",
    "We can get a data point, specyfing the schema, namespace and the id. We also pass a [fieldSet](https://docs.vespa.ai/en/reference/document-v1-api-reference.html#fieldset) \n",
    "parameter that uses a built in set `[all]` that also will return the synthetic fields. This also returns the result of the indexing converters (the embedding tensor and the utc\n",
    "epoch timestamp). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0e9ef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pathId\": \"/document/v1/assistant/mail/group/bergum@vespa.ai/1\",\n",
      "  \"id\": \"id:assistant:mail:g=bergum@vespa.ai:1\",\n",
      "  \"fields\": {\n",
      "    \"body\": \"Hello Llama Friends \\ud83e\\udd99 LlamaIndex is 1 year old this week! \\ud83c\\udf89 To celebrate, we're taking a stroll down memory \\n                    lane on our blog with twelve milestones from our first year. Be sure to check it out.\",\n",
      "    \"timestamp\": 1700038800,\n",
      "    \"display_date\": \"2023-11-15T09:00:00Z\",\n",
      "    \"from\": \"news@llamaindex.ai\",\n",
      "    \"to\": \"bergum@vespa.ai\",\n",
      "    \"embedding\": {\n",
      "      \"type\": \"tensor<bfloat16>(x[384])\",\n",
      "      \"values\": [\n",
      "        -0.83984375,\n",
      "        0.322265625,\n",
      "        0.431640625,\n",
      "        -0.1083984375,\n",
      "        -0.1357421875,\n",
      "        0.263671875,\n",
      "        0.388671875,\n",
      "        -0.310546875,\n",
      "        0.2041015625,\n",
      "        0.5078125,\n",
      "        0.486328125,\n",
      "        -0.076171875,\n",
      "        0.125,\n",
      "        0.1552734375,\n",
      "        -0.08154296875,\n",
      "        -0.349609375,\n",
      "        -0.21875,\n",
      "        0.212890625,\n",
      "        -1.046875,\n",
      "        0.2099609375,\n",
      "        0.4921875,\n",
      "        -0.51171875,\n",
      "        -0.1474609375,\n",
      "        -0.421875,\n",
      "        0.018798828125,\n",
      "        0.07470703125,\n",
      "        0.62890625,\n",
      "        0.359375,\n",
      "        -0.39453125,\n",
      "        -1.25,\n",
      "        -0.416015625,\n",
      "        0.002044677734375,\n",
      "        0.0751953125,\n",
      "        -0.22265625,\n",
      "        0.39453125,\n",
      "        -0.103515625,\n",
      "        0.310546875,\n",
      "        0.380859375,\n",
      "        0.0186767578125,\n",
      "        0.65234375,\n",
      "        -0.30078125,\n",
      "        -0.365234375,\n",
      "        0.0361328125,\n",
      "        -0.30078125,\n",
      "        -0.2099609375,\n",
      "        -0.09326171875,\n",
      "        -0.42578125,\n",
      "        -0.298828125,\n",
      "        0.5625,\n",
      "        -0.044677734375,\n",
      "        -0.84765625,\n",
      "        -0.3046875,\n",
      "        0.70703125,\n",
      "        0.26953125,\n",
      "        -0.2373046875,\n",
      "        0.765625,\n",
      "        0.228515625,\n",
      "        0.1376953125,\n",
      "        0.45703125,\n",
      "        0.33984375,\n",
      "        -0.203125,\n",
      "        0.130859375,\n",
      "        -1.3515625,\n",
      "        0.8046875,\n",
      "        0.4140625,\n",
      "        0.45703125,\n",
      "        0.061279296875,\n",
      "        -0.0634765625,\n",
      "        -0.4375,\n",
      "        -0.2021484375,\n",
      "        0.2314453125,\n",
      "        0.369140625,\n",
      "        0.333984375,\n",
      "        0.341796875,\n",
      "        -0.3359375,\n",
      "        0.4296875,\n",
      "        0.294921875,\n",
      "        0.64453125,\n",
      "        -0.07763671875,\n",
      "        -0.16796875,\n",
      "        -0.06494140625,\n",
      "        -0.6875,\n",
      "        -0.43359375,\n",
      "        0.0186767578125,\n",
      "        -0.341796875,\n",
      "        -0.48046875,\n",
      "        0.369140625,\n",
      "        0.42578125,\n",
      "        -0.412109375,\n",
      "        -0.294921875,\n",
      "        -0.2265625,\n",
      "        -0.330078125,\n",
      "        0.13671875,\n",
      "        -0.28515625,\n",
      "        -0.359375,\n",
      "        -0.197265625,\n",
      "        0.240234375,\n",
      "        0.043212890625,\n",
      "        -0.7265625,\n",
      "        0.55859375,\n",
      "        0.0478515625,\n",
      "        0.28125,\n",
      "        -0.1474609375,\n",
      "        0.0007781982421875,\n",
      "        0.07177734375,\n",
      "        -0.09765625,\n",
      "        -0.029541015625,\n",
      "        0.083984375,\n",
      "        0.2236328125,\n",
      "        -0.2255859375,\n",
      "        -0.263671875,\n",
      "        -0.1279296875,\n",
      "        0.18359375,\n",
      "        -0.349609375,\n",
      "        0.1611328125,\n",
      "        0.1611328125,\n",
      "        -0.298828125,\n",
      "        -0.4921875,\n",
      "        -0.2734375,\n",
      "        0.251953125,\n",
      "        0.65234375,\n",
      "        -0.095703125,\n",
      "        0.255859375,\n",
      "        -0.451171875,\n",
      "        0.6953125,\n",
      "        -0.173828125,\n",
      "        0.54296875,\n",
      "        0.56640625,\n",
      "        0.33984375,\n",
      "        -0.27734375,\n",
      "        0.41015625,\n",
      "        0.201171875,\n",
      "        0.380859375,\n",
      "        -0.203125,\n",
      "        -0.435546875,\n",
      "        -0.062255859375,\n",
      "        -0.37109375,\n",
      "        -0.361328125,\n",
      "        0.267578125,\n",
      "        0.1298828125,\n",
      "        -0.40625,\n",
      "        -0.2578125,\n",
      "        -0.11572265625,\n",
      "        -0.6640625,\n",
      "        -0.10595703125,\n",
      "        0.37109375,\n",
      "        -0.251953125,\n",
      "        0.3515625,\n",
      "        -0.64453125,\n",
      "        -0.26171875,\n",
      "        -0.4296875,\n",
      "        -0.154296875,\n",
      "        0.2236328125,\n",
      "        -0.2373046875,\n",
      "        0.1728515625,\n",
      "        0.40234375,\n",
      "        -0.11474609375,\n",
      "        0.310546875,\n",
      "        -0.26171875,\n",
      "        0.2119140625,\n",
      "        -0.69140625,\n",
      "        -0.3984375,\n",
      "        0.279296875,\n",
      "        0.49609375,\n",
      "        0.189453125,\n",
      "        -0.890625,\n",
      "        0.056396484375,\n",
      "        -0.01165771484375,\n",
      "        -0.011474609375,\n",
      "        -0.3984375,\n",
      "        -0.1328125,\n",
      "        0.5,\n",
      "        0.1875,\n",
      "        -0.404296875,\n",
      "        0.7890625,\n",
      "        -0.296875,\n",
      "        0.142578125,\n",
      "        -0.484375,\n",
      "        0.59375,\n",
      "        -0.51171875,\n",
      "        -0.016845703125,\n",
      "        -0.3828125,\n",
      "        -0.384765625,\n",
      "        0.56640625,\n",
      "        0.59375,\n",
      "        -0.1416015625,\n",
      "        -0.51953125,\n",
      "        -0.12255859375,\n",
      "        0.205078125,\n",
      "        -0.412109375,\n",
      "        -0.46484375,\n",
      "        -0.25390625,\n",
      "        -0.341796875,\n",
      "        0.44921875,\n",
      "        0.439453125,\n",
      "        0.49609375,\n",
      "        -0.40625,\n",
      "        -0.1845703125,\n",
      "        -0.060302734375,\n",
      "        -0.36328125,\n",
      "        0.6484375,\n",
      "        -0.0205078125,\n",
      "        -0.12353515625,\n",
      "        0.431640625,\n",
      "        -0.255859375,\n",
      "        0.10498046875,\n",
      "        0.390625,\n",
      "        -0.5078125,\n",
      "        -0.041748046875,\n",
      "        0.181640625,\n",
      "        -0.36328125,\n",
      "        -0.02001953125,\n",
      "        -0.1533203125,\n",
      "        -0.640625,\n",
      "        0.07763671875,\n",
      "        -0.0029296875,\n",
      "        0.1171875,\n",
      "        -0.0230712890625,\n",
      "        0.5390625,\n",
      "        0.171875,\n",
      "        0.1611328125,\n",
      "        -0.58984375,\n",
      "        -0.3671875,\n",
      "        -0.91015625,\n",
      "        0.232421875,\n",
      "        -0.458984375,\n",
      "        -0.37109375,\n",
      "        0.0712890625,\n",
      "        -0.07763671875,\n",
      "        -0.0130615234375,\n",
      "        0.15234375,\n",
      "        0.37109375,\n",
      "        0.056640625,\n",
      "        0.51171875,\n",
      "        -0.123046875,\n",
      "        0.1474609375,\n",
      "        -0.05712890625,\n",
      "        -0.12109375,\n",
      "        0.5078125,\n",
      "        -0.1201171875,\n",
      "        0.3046875,\n",
      "        0.78515625,\n",
      "        -0.21875,\n",
      "        -0.3359375,\n",
      "        -1.015625,\n",
      "        -0.3203125,\n",
      "        -0.8125,\n",
      "        -0.109375,\n",
      "        -0.384765625,\n",
      "        0.9765625,\n",
      "        0.59765625,\n",
      "        0.45703125,\n",
      "        -0.2890625,\n",
      "        0.1611328125,\n",
      "        0.197265625,\n",
      "        0.16015625,\n",
      "        -0.5234375,\n",
      "        0.35546875,\n",
      "        -0.35546875,\n",
      "        -0.1455078125,\n",
      "        0.171875,\n",
      "        -0.416015625,\n",
      "        -0.1943359375,\n",
      "        0.09716796875,\n",
      "        0.13671875,\n",
      "        0.236328125,\n",
      "        -0.578125,\n",
      "        0.427734375,\n",
      "        -0.29296875,\n",
      "        -0.28125,\n",
      "        0.2216796875,\n",
      "        -0.059814453125,\n",
      "        -0.396484375,\n",
      "        0.318359375,\n",
      "        -0.263671875,\n",
      "        0.46484375,\n",
      "        -0.0771484375,\n",
      "        -0.59375,\n",
      "        -0.193359375,\n",
      "        -0.13671875,\n",
      "        0.31640625,\n",
      "        -0.232421875,\n",
      "        0.06884765625,\n",
      "        -0.578125,\n",
      "        -0.1787109375,\n",
      "        0.43359375,\n",
      "        -0.16796875,\n",
      "        0.451171875,\n",
      "        0.50390625,\n",
      "        -0.0172119140625,\n",
      "        -0.0048828125,\n",
      "        -0.2041015625,\n",
      "        -0.68359375,\n",
      "        -0.11474609375,\n",
      "        0.70703125,\n",
      "        -0.16796875,\n",
      "        -0.0517578125,\n",
      "        0.234375,\n",
      "        -0.07177734375,\n",
      "        0.359375,\n",
      "        -0.0230712890625,\n",
      "        -0.205078125,\n",
      "        -0.2890625,\n",
      "        -0.2451171875,\n",
      "        -0.74609375,\n",
      "        0.7734375,\n",
      "        0.494140625,\n",
      "        0.291015625,\n",
      "        -0.271484375,\n",
      "        -0.30078125,\n",
      "        0.24609375,\n",
      "        0.25,\n",
      "        -0.72265625,\n",
      "        0.435546875,\n",
      "        -0.31640625,\n",
      "        0.70703125,\n",
      "        0.11669921875,\n",
      "        0.11865234375,\n",
      "        -0.609375,\n",
      "        -1.0703125,\n",
      "        0.015625,\n",
      "        0.345703125,\n",
      "        0.103515625,\n",
      "        0.224609375,\n",
      "        0.29296875,\n",
      "        0.353515625,\n",
      "        -0.146484375,\n",
      "        -0.07080078125,\n",
      "        -0.357421875,\n",
      "        0.373046875,\n",
      "        0.2392578125,\n",
      "        0.6171875,\n",
      "        -0.59765625,\n",
      "        -0.0201416015625,\n",
      "        0.546875,\n",
      "        -0.162109375,\n",
      "        0.298828125,\n",
      "        -0.0283203125,\n",
      "        -0.380859375,\n",
      "        0.322265625,\n",
      "        0.431640625,\n",
      "        1.015625,\n",
      "        0.150390625,\n",
      "        0.119140625,\n",
      "        0.3203125,\n",
      "        0.1005859375,\n",
      "        0.1904296875,\n",
      "        -0.0380859375,\n",
      "        0.205078125,\n",
      "        -0.1416015625,\n",
      "        -0.32421875,\n",
      "        1.0390625,\n",
      "        -0.1005859375,\n",
      "        0.01312255859375,\n",
      "        0.5625,\n",
      "        -0.41015625,\n",
      "        -0.1552734375,\n",
      "        0.19140625,\n",
      "        -0.10595703125,\n",
      "        0.59765625,\n",
      "        0.515625,\n",
      "        -0.255859375,\n",
      "        0.05322265625,\n",
      "        0.8359375,\n",
      "        -0.12890625,\n",
      "        -0.361328125,\n",
      "        0.1875,\n",
      "        -0.357421875,\n",
      "        -0.41015625,\n",
      "        -0.40625,\n",
      "        0.2041015625,\n",
      "        0.6328125,\n",
      "        0.404296875,\n",
      "        0.400390625,\n",
      "        -0.478515625,\n",
      "        -0.404296875,\n",
      "        0.045166015625,\n",
      "        -0.404296875,\n",
      "        -0.37890625,\n",
      "        0.033935546875,\n",
      "        0.039306640625,\n",
      "        0.5625,\n",
      "        0.3046875,\n",
      "        0.291015625\n",
      "      ]\n",
      "    },\n",
      "    \"subject\": \"LlamaIndex news, 2023-11-14\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from vespa.io import VespaResponse\n",
    "import json\n",
    "\n",
    "response:VespaResponse = app.get_data(schema=\"mail\", namespace=\"assistant\", \n",
    "    data_id=\"1\",\n",
    "    groupname=\"bergum@vespa.ai\", fieldSet=\"[all]\")\n",
    "assert(response.is_successful())\n",
    "print(json.dumps(response.json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003125e",
   "metadata": {},
   "source": [
    "Compare that with using the default fieldSet parameter `[document]` that only returns the fields that we sent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4edf2aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pathId\": \"/document/v1/assistant/mail/group/bergum@vespa.ai/1\",\n",
      "  \"id\": \"id:assistant:mail:g=bergum@vespa.ai:1\",\n",
      "  \"fields\": {\n",
      "    \"body\": \"Hello Llama Friends \\ud83e\\udd99 LlamaIndex is 1 year old this week! \\ud83c\\udf89 To celebrate, we're taking a stroll down memory \\n                    lane on our blog with twelve milestones from our first year. Be sure to check it out.\",\n",
      "    \"display_date\": \"2023-11-15T09:00:00Z\",\n",
      "    \"from\": \"news@llamaindex.ai\",\n",
      "    \"to\": \"bergum@vespa.ai\",\n",
      "    \"subject\": \"LlamaIndex news, 2023-11-14\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response:VespaResponse = app.get_data(schema=\"mail\", namespace=\"assistant\", \n",
    "    data_id=\"1\",\n",
    "    groupname=\"bergum@vespa.ai\", fieldSet=\"[document]\")\n",
    "assert(response.is_successful())\n",
    "print(json.dumps(response.json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b007ec",
   "metadata": {},
   "source": [
    "### Querying data\n",
    "\n",
    "Now, we can also query our data. When using [streaming mode](https://docs.vespa.ai/en/reference/query-api-reference.html#streaming), \n",
    "we must pass the `groupname` parameter. The query request uses the Vespa Query API where `PyVespa` allows passing any of the Vespa query api parameters\n",
    "using `**kwargs`. Read more about querying Vespa in:\n",
    "\n",
    "- [Vespa Query API](https://docs.vespa.ai/en/query-api.html)\n",
    "- [Vespa Query API reference](https://docs.vespa.ai/en/reference/query-api-reference.html)\n",
    "- [Vespa Query Language API (YQL)](https://docs.vespa.ai/en/query-language.html)\n",
    "\n",
    "Sample query request for `when is my dentist appointment` for the user `bergum@vespa.ai`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d8b072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"id:assistant:mail:g=bergum@vespa.ai:2\",\n",
      "  \"relevance\": 1.2115380480627955,\n",
      "  \"source\": \"assistant_content.mail\",\n",
      "  \"fields\": {\n",
      "    \"matchfeatures\": {\n",
      "      \"freshness(timestamp)\": 1.0,\n",
      "      \"nativeRank(body)\": 0.09246780326887034,\n",
      "      \"nativeRank(subject)\": 0.11907024479392506,\n",
      "      \"my_function\": 1.2115380480627955\n",
      "    },\n",
      "    \"subject\": \"Dentist Appointment Reminder\",\n",
      "    \"to\": \"bergum@vespa.ai\",\n",
      "    \"display_date\": \"2023-11-20T15:30:00Z\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from vespa.io import VespaQueryResponse\n",
    "\n",
    "response:VespaQueryResponse = app.query(\n",
    "    yql=\"select subject, display_date, to from sources mail where userQuery()\",\n",
    "    query=\"when is my dentist appointment\", \n",
    "    groupname=\"bergum@vespa.ai\", \n",
    "    ranking=\"default\"\n",
    ")\n",
    "assert(response.is_successful())\n",
    "print(json.dumps(response.hits[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77beb5a",
   "metadata": {},
   "source": [
    "For the above query request, Vespa searched the `default` fieldset which we defined in the schema to match against several fields including the body and the subject. The `default`\n",
    "rank-profile calculated the relevance score as the sum of three rank-features: `nativeRank(body)` + `nativeRank(subject)` + `freshness(timestamp)` and the result of this computation is the\n",
    "`relevance` score of the hit. In addition, we also asked for Vespa to return `match-features` that can be used to debug the `relevance` score or for feature logging. \n",
    "\n",
    "Now, we can try the `semantic` ranking profile, using Vespa's support for nearestNeighbor search also for streaming mode. Again, we\n",
    "must specify the `groupname`. This also examplifies how to use the configured `e5` embedder to embed the user query \n",
    "into an embedding representation. See [embedding a query text](https://docs.vespa.ai/en/embedding.html#embedding-a-query-text) for more usage examples of using Vespa embedders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9349fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"id:assistant:mail:g=bergum@vespa.ai:2\",\n",
      "  \"relevance\": 0.9079386507883569,\n",
      "  \"source\": \"assistant_content.mail\",\n",
      "  \"fields\": {\n",
      "    \"matchfeatures\": {\n",
      "      \"distance(field,embedding)\": 0.4324572498488368,\n",
      "      \"freshness(timestamp)\": 1.0,\n",
      "      \"cosine\": 0.9079386507883569\n",
      "    },\n",
      "    \"subject\": \"Dentist Appointment Reminder\",\n",
      "    \"display_date\": \"2023-11-20T15:30:00Z\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from vespa.io import VespaQueryResponse\n",
    "\n",
    "response:VespaQueryResponse = app.query(\n",
    "    yql=\"select subject, display_date from mail where {targetHits:10}nearestNeighbor(embedding,q)\",\n",
    "    groupname=\"bergum@vespa.ai\", \n",
    "    ranking=\"semantic\",\n",
    "    body={\n",
    "        \"input.query(q)\": \"embed(e5, \\\"when is my dentist appointment\\\")\",\n",
    "    }\n",
    ")\n",
    "assert(response.is_successful())\n",
    "print(json.dumps(response.hits[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad4fcd",
   "metadata": {},
   "source": [
    "Notice now that the relevance score is different since the `semantic` rank-profile defined in our schema used `cos(distance(field,embedding))` calculating \n",
    "the cosine similarity between the query embedding vector and the document embedding vector. We can try the same query for a different user (`penguin@antarctica.ai`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af43be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"id:assistant:mail:g=penguin@antarctica.ai:1\",\n",
      "  \"relevance\": 0.7491816233633459,\n",
      "  \"source\": \"assistant_content.mail\",\n",
      "  \"fields\": {\n",
      "    \"matchfeatures\": {\n",
      "      \"distance(field,embedding)\": 0.7239706506184826,\n",
      "      \"freshness(timestamp)\": 1.0,\n",
      "      \"cosine\": 0.7491816233633459\n",
      "    },\n",
      "    \"subject\": \"Antarctica Expedition: Penguin Chronicles\",\n",
      "    \"display_date\": \"2023-11-25T11:45:00Z\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from vespa.io import VespaQueryResponse\n",
    "\n",
    "response:VespaQueryResponse = app.query(\n",
    "    yql=\"select subject, display_date from mail where {targetHits:10}nearestNeighbor(embedding,q)\",\n",
    "    groupname=\"penguin@antarctica.ai\", \n",
    "    ranking=\"semantic\",\n",
    "    body={\n",
    "        \"input.query(q)\": \"embed(e5, \\\"when is my dentist appointment\\\")\",\n",
    "    }\n",
    ")\n",
    "assert(response.is_successful())\n",
    "print(json.dumps(response.hits[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce1d7d",
   "metadata": {},
   "source": [
    "Notice that this query restricted to the user/groupname `penguin@antarctica.ai` and for this user there aren't any relevant hits, but nearestNeighbor\n",
    "search will still retrieve as there is no distinction between a match, all documents are neighbors, it's just that the distance differs. \n",
    "\n",
    "This is solvable either by passing [distanceThreshold](https://docs.vespa.ai/en/nearest-neighbor-search-guide.html#strict-filters-and-distant-neighbors) or\n",
    "custom [drop ranking expressions](https://docs.vespa.ai/en/faq#how-to-set-a-dynamic-query-time-ranking-drop-threshold) using any feature combination.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2a4ad",
   "metadata": {},
   "source": [
    "## LlamaIndex Retrievers Introduction\n",
    "\n",
    "Now, we have a basic Vespa app using streaming mode up. For building an end to end assistant, we likely want to\n",
    "use a LLM framework like¬†[LangChain](https://www.langchain.com/) or [LLamaIndex](https://www.llamaindex.ai/). In this example \n",
    "we use LLamaIndex retrievers. \n",
    "\n",
    "LlamaIndex [retriever](https://gpt-index.readthedocs.io/en/latest/core_modules/query_modules/retriever/root.html)\n",
    "abstraction allows developers to add custom retrievers that retrieve information in Retrieval Augmented Generation (RAG) pipelines. \n",
    "\n",
    "For a good introduction to LLamaIndex and it's concepts, see [LLamaIndex High-Level Concepts](https://gpt-index.readthedocs.io/en/latest/getting_started/concepts.html).\n",
    "\n",
    "\n",
    "In our example, we connect a custom LLamaIndex retriever with the deployed Vespa app. \n",
    "\n",
    "To create a custom LlamaIndex Retriever we implement a class that inherts from `llama_index.retrievers.BaseRetriever.BaseRetriever` and \n",
    "which  implements `_retrieve(query)`. \n",
    "\n",
    "A simple `PersonalAssistantVespaRetriever` could look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ac21f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import llama_index.retrievers\n",
    "from llama_index.schema import  Document, NodeWithScore\n",
    "from llama_index.indices.query.schema import QueryBundle\n",
    "\n",
    "from vespa.application import Vespa\n",
    "from vespa.io import VespaQueryResponse\n",
    "\n",
    "from typing import List, Union\n",
    "\n",
    "class PersonalAssistantVespaRetriever(llama_index.retrievers.BaseRetriever):\n",
    "\n",
    "   def __init__(\n",
    "      self,\n",
    "      app: Vespa,\n",
    "      user: str,\n",
    "      hits: int = 5,\n",
    "      vespa_rank_profile: str = \"default\",\n",
    "      fields: List[str] = [\"subject\", \"body\"]\n",
    "   ) -> None:\n",
    "      \"\"\"Retriever for the Personal Assistant application.\n",
    "      Args:\n",
    "      param: app: Vespa application object\n",
    "      param: user: user id to retrieve documents for (used for streaming groupname)\n",
    "      param: hits: number of hits to retrieve from Vespa app\n",
    "      param: vespa_rank_profile: Vespa rank profile to use\n",
    "      param: fields: fields to retrieve\n",
    "      \"\"\"\n",
    " \n",
    "      self.app = app\n",
    "      self.hits = hits\n",
    "      self.user = user\n",
    "      self.vespa_rank_profile = vespa_rank_profile\n",
    "      self.fields = fields\n",
    "      self.summary_fields = \",\".join(fields)\n",
    "\n",
    "   def _retrieve(self, query:Union[str,QueryBundle]) -> List[NodeWithScore]:\n",
    "      \"\"\"Retrieve documents from Vespa application.\n",
    "      \"\"\"\n",
    "      if isinstance(query, QueryBundle):\n",
    "         query = query.query_str\n",
    "      \n",
    "      if self.vespa_rank_profile == 'default':\n",
    "         yql:str = f\"select {self.summary_fields} from mail where userQuery()\"\n",
    "      else:\n",
    "         yql = f\"select {self.summary_fields} from mail where {{targetHits:10}}nearestNeighbor(embedding,q) or userQuery()\"\n",
    "      vespa_body_request = {\n",
    "         \"yql\" : yql,\n",
    "         \"query\": query,\n",
    "         \"hits\": self.hits,\n",
    "         \"ranking.profile\": self.vespa_rank_profile,\n",
    "         \"timeout\": \"1s\",\n",
    "      }\n",
    "      if self.vespa_rank_profile != \"default\":\n",
    "         vespa_body_request[\"input.query(q)\"] = f\"embed(e5, \\\"{query}\\\")\"\n",
    "\n",
    "      with self.app.syncio(connections=1) as session:\n",
    "         response:VespaQueryResponse = session.query(body=vespa_body_request, groupname=self.user)\n",
    "         if not response.is_successful():\n",
    "            raise ValueError(f\"Query request failed: {response.status_code}, response payload: {response.get_json()}\")\n",
    "\n",
    "      nodes: List[NodeWithScore] = []\n",
    "      for hit in response.hits:\n",
    "         response_fields:dict = hit.get('fields', {})\n",
    "         text: str = \"\"\n",
    "         for field in response_fields.keys():\n",
    "            if isinstance(response_fields[field], str) and field in self.fields:\n",
    "                  text += response_fields[field] + \" \"\n",
    "         id = hit['id']\n",
    "         doc = Document(id_=id, text=text, \n",
    "            metadata=response_fields,    \n",
    "         )\n",
    "         nodes.append(NodeWithScore(node=doc, score=hit['relevance']))    \n",
    "      return nodes                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1188a1e3",
   "metadata": {},
   "source": [
    "The above defines a `PersonalAssistantVespaRetriever` which accepts most importantly a [pyvespa](https://pyvespa.readthedocs.io/en/latest/)\n",
    "`Vespa` application instance. \n",
    "\n",
    "The YQL specifies a hybrid retrieval query that retrieves both using embedding-based retrieval (vector search) \n",
    "using Vespa's nearest neighbor search operator in combination with traditional keyword matching.  \n",
    "\n",
    "Then it reads the Vespa [search result JSON response](https://docs.vespa.ai/en/reference/default-result-format.html)\n",
    "wrapped by a [VespaQueryResponse ](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespaqueryresponse). \n",
    "\n",
    "With the above, we can connect to the running Vespa app and initialize the `PersonalAssistantVespaRetriever` \n",
    "for the user `bergum@vespa.ai`. The `user` argument is passed as the Vespa [streaming search groupname\n",
    "parameter](https://docs.vespa.ai/en/reference/query-api-reference.html#streaming.groupname). This effectively limits the \n",
    "data that Vespa needs to stream through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "707a3fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=Document(id_='id:assistant:mail:g=bergum@vespa.ai:2', embedding=None, metadata={'matchfeatures': {'freshness(timestamp)': 1.0, 'nativeRank(body)': 0.09246780326887034, 'nativeRank(subject)': 0.11907024479392506, 'my_function': 1.2115380480627955}, 'subject': 'Dentist Appointment Reminder', 'body': 'Dear Jo Kristian ,\\nThis is a reminder for your upcoming dentist appointment on 2023-12-04 at 09:30. Please arrive 15 minutes early.\\nBest regards,\\nDr. Dentist'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7dc7e72dbad349461957058218f4dab0b031e2a91a3f8e4d404994d6af2cde93', text='Dentist Appointment Reminder Dear Jo Kristian ,\\nThis is a reminder for your upcoming dentist appointment on 2023-12-04 at 09:30. Please arrive 15 minutes early.\\nBest regards,\\nDr. Dentist ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=1.2115380480627955),\n",
       " NodeWithScore(node=Document(id_='id:assistant:mail:g=bergum@vespa.ai:1', embedding=None, metadata={'matchfeatures': {'freshness(timestamp)': 0.9958644547325103, 'nativeRank(body)': 0.02919821398130037, 'nativeRank(subject)': 1.3512214436142505e-38, 'my_function': 1.0250626687138107}, 'subject': 'LlamaIndex news, 2023-11-14', 'body': \"Hello Llama Friends ü¶ô LlamaIndex is 1 year old this week! üéâ To celebrate, we're taking a stroll down memory \\n                    lane on our blog with twelve milestones from our first year. Be sure to check it out.\"}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='619abcf2d350579484d711eb5ab11e24c8a0eecce3ca55f3f50f78f07b5088c6', text=\"LlamaIndex news, 2023-11-14 Hello Llama Friends ü¶ô LlamaIndex is 1 year old this week! üéâ To celebrate, we're taking a stroll down memory \\n                    lane on our blog with twelve milestones from our first year. Be sure to check it out. \", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=1.0250626687138107)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "retriever = PersonalAssistantVespaRetriever(\n",
    "    app=app, \n",
    "    user=\"bergum@vespa.ai\", \n",
    "    vespa_rank_profile=\"default\"\n",
    ")\n",
    "retriever.retrieve(\"When is my dentist appointment?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1eaf45",
   "metadata": {},
   "source": [
    "There we have the top ranking `NodeWithScore`, that could be used for downstream generation. We can also use a different Vespa\n",
    "[ranking](https://docs.vespa.ai/en/ranking.html) profile. The above used `default` which will be Vespa's [nativeRank](https://docs.vespa.ai/en/nativerank.html) text matching feature. We can also use a different (configured) Vespa rank-profile. Now we can notice that the `score` takes a different value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cfc3477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=Document(id_='id:assistant:mail:g=bergum@vespa.ai:2', embedding=None, metadata={'matchfeatures': {'distance(field,embedding)': 0.43945494361938975, 'freshness(timestamp)': 1.0, 'cosine': 0.9049836898369259}, 'subject': 'Dentist Appointment Reminder', 'body': 'Dear Jo Kristian ,\\nThis is a reminder for your upcoming dentist appointment on 2023-12-04 at 09:30. Please arrive 15 minutes early.\\nBest regards,\\nDr. Dentist'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4bec670f4b497fea7c9cbe31b73abaf305514e2533467df281fba2a38676ace2', text='Dentist Appointment Reminder Dear Jo Kristian ,\\nThis is a reminder for your upcoming dentist appointment on 2023-12-04 at 09:30. Please arrive 15 minutes early.\\nBest regards,\\nDr. Dentist ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.9049836898369259),\n",
       " NodeWithScore(node=Document(id_='id:assistant:mail:g=bergum@vespa.ai:1', embedding=None, metadata={'matchfeatures': {'distance(field,embedding)': 0.69930099954744, 'freshness(timestamp)': 0.9958643261316873, 'cosine': 0.7652923088511814}, 'subject': 'LlamaIndex news, 2023-11-14', 'body': \"Hello Llama Friends ü¶ô LlamaIndex is 1 year old this week! üéâ To celebrate, we're taking a stroll down memory \\n                    lane on our blog with twelve milestones from our first year. Be sure to check it out.\"}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='f36eb124acf2cb2268bc015762f83056a2583a82c4001f1314297b53d64647d4', text=\"LlamaIndex news, 2023-11-14 Hello Llama Friends ü¶ô LlamaIndex is 1 year old this week! üéâ To celebrate, we're taking a stroll down memory \\n                    lane on our blog with twelve milestones from our first year. Be sure to check it out. \", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7652923088511814)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = PersonalAssistantVespaRetriever(\n",
    "    app=app, \n",
    "    user=\"bergum@vespa.ai\", \n",
    "    vespa_rank_profile=\"semantic\"\n",
    ")\n",
    "retriever.retrieve(\"When is my dentist appointment?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be09b78",
   "metadata": {},
   "source": [
    "### Rank fusion\n",
    "\n",
    "So far we demonstrated ranking using freshness, keyword matching and semantic. Now if we want to combine these without having to think much about \n",
    "the score distributions of these features, we can turn to [reciprocal_rank_fusion](https://docs.vespa.ai/en/phased-ranking.html#cross-hit-normalization-including-reciprocal-rank-fusion). \n",
    "\n",
    "We deploy this as a final phase ranking where we fuse two different functions:\n",
    "\n",
    "- The semantic vector matching\n",
    "- Keywords and freshness \n",
    "\n",
    "We deploy a new rank-profile with the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c32c5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import  RankProfile,  Function, GlobalPhaseRanking\n",
    "\n",
    "fusion = RankProfile(\n",
    "    name=\"fusion\",\n",
    "    inherits=\"semantic\",\n",
    "    functions=[\n",
    "        Function(\n",
    "            name=\"keywords_and_freshness\", expression=\" nativeRank(subject) + nativeRank(body) + freshness(timestamp)\"\n",
    "        ),\n",
    "        Function(\n",
    "            name=\"semantic\", expression=\"cos(distance(field,embedding))\"\n",
    "        )\n",
    "\n",
    "    ],\n",
    "    first_phase=\"keywords_and_freshness\",\n",
    "    match_features=[\"nativeRank(subject)\", \"nativeRank(body)\", \"keywords_and_freshness\", \"freshness(timestamp)\", \"semantic\"],\n",
    "    global_phase=GlobalPhaseRanking(\n",
    "        rerank_count=1000,\n",
    "        expression=\"reciprocal_rank_fusion(semantic, keywords_and_freshness)\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee9554",
   "metadata": {},
   "source": [
    "Add this new `rank-profile` to the schema and re-deploy the application to Vespa Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "039ec3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment started in run 5 of dev-aws-us-east-1c for samples.assistant. This may take about 15 minutes the first time.\n",
      "INFO    [17:55:59]  Deploying platform version 8.259.15 and application dev build 5 for dev-aws-us-east-1c of default ...\n",
      "INFO    [17:56:00]  Using CA signed certificate version 0\n",
      "INFO    [17:56:00]  Using 1 nodes in container cluster 'assistant_container'\n",
      "WARNING [17:56:00]  For streaming search cluster 'assistant_content.mail', SD field 'embedding': hnsw index is not relevant and not supported, ignoring setting\n",
      "WARNING [17:56:00]  For streaming search cluster 'assistant_content.mail', SD field 'embedding': hnsw index is not relevant and not supported, ignoring setting\n",
      "INFO    [17:56:02]  Deployment successful.\n",
      "INFO    [17:56:02]  Session 2759 for tenant 'samples' prepared and activated.\n",
      "INFO    [17:56:02]  ######## Details for all nodes ########\n",
      "INFO    [17:56:02]  h88962b.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [17:56:02]  --- platform vespa/cloud-tenant-rhel8:8.259.15\n",
      "INFO    [17:56:02]  --- storagenode on port 19102 has config generation 2758, wanted is 2759\n",
      "INFO    [17:56:02]  --- searchnode on port 19107 has config generation 2759, wanted is 2759\n",
      "INFO    [17:56:02]  --- distributor on port 19111 has config generation 2758, wanted is 2759\n",
      "INFO    [17:56:02]  --- metricsproxy-container on port 19092 has config generation 2759, wanted is 2759\n",
      "INFO    [17:56:02]  h88969f.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [17:56:02]  --- platform vespa/cloud-tenant-rhel8:8.259.15\n",
      "INFO    [17:56:02]  --- container-clustercontroller on port 19050 has config generation 2759, wanted is 2759\n",
      "INFO    [17:56:02]  --- metricsproxy-container on port 19092 has config generation 2759, wanted is 2759\n",
      "INFO    [17:56:02]  h88978a.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [17:56:02]  --- platform vespa/cloud-tenant-rhel8:8.259.15\n",
      "INFO    [17:56:02]  --- logserver-container on port 4080 has config generation 2759, wanted is 2759\n",
      "INFO    [17:56:02]  --- metricsproxy-container on port 19092 has config generation 2759, wanted is 2759\n",
      "INFO    [17:56:02]  h89128a.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [17:56:02]  --- platform vespa/cloud-tenant-rhel8:8.259.15\n",
      "INFO    [17:56:02]  --- container on port 4080 has config generation 2758, wanted is 2759\n",
      "INFO    [17:56:02]  --- metricsproxy-container on port 19092 has config generation 2759, wanted is 2759\n",
      "INFO    [17:56:21]  Found endpoints:\n",
      "INFO    [17:56:21]  - dev.aws-us-east-1c\n",
      "INFO    [17:56:21]   |-- https://e09d41ab.cae25ac9.z.vespa-app.cloud/ (cluster 'assistant_container')\n",
      "INFO    [17:56:21]  Installation succeeded!\n",
      "Using mTLS (key,cert) Authentication against endpoint https://e09d41ab.cae25ac9.z.vespa-app.cloud//ApplicationStatus\n",
      "Application is up!\n",
      "Finished deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Vespa(https://e09d41ab.cae25ac9.z.vespa-app.cloud/)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail_schema.add_rank_profile(fusion)\n",
    "vespa_cloud.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9d077",
   "metadata": {},
   "source": [
    "Run a query with the new `fusion` ranking profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf592295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=Document(id_='id:assistant:mail:g=bergum@vespa.ai:2', embedding=None, metadata={'matchfeatures': {'freshness(timestamp)': 1.0, 'nativeRank(body)': 0.09246780326887034, 'nativeRank(subject)': 0.11907024479392506, 'keywords_and_freshness': 1.2115380480627955, 'semantic': 0.9049836898369259}, 'subject': 'Dentist Appointment Reminder', 'body': 'Dear Jo Kristian ,\\nThis is a reminder for your upcoming dentist appointment on 2023-12-04 at 09:30. Please arrive 15 minutes early.\\nBest regards,\\nDr. Dentist'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b2580398d53e8071b11a1040f900e6a4fdf264e1a4c7ebb5838f8729f3bc1674', text='Dentist Appointment Reminder Dear Jo Kristian ,\\nThis is a reminder for your upcoming dentist appointment on 2023-12-04 at 09:30. Please arrive 15 minutes early.\\nBest regards,\\nDr. Dentist ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.03278688524590164),\n",
       " NodeWithScore(node=Document(id_='id:assistant:mail:g=bergum@vespa.ai:1', embedding=None, metadata={'matchfeatures': {'freshness(timestamp)': 0.9958611111111111, 'nativeRank(body)': 0.02919821398130037, 'nativeRank(subject)': 1.3512214436142505e-38, 'keywords_and_freshness': 1.0250593250924114, 'semantic': 0.7652923088511814}, 'subject': 'LlamaIndex news, 2023-11-14', 'body': \"Hello Llama Friends ü¶ô LlamaIndex is 1 year old this week! üéâ To celebrate, we're taking a stroll down memory \\n                    lane on our blog with twelve milestones from our first year. Be sure to check it out.\"}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4048b6f2a82bf0c81bf2e7692229108fc7c97506f97e983872589b4ab73d5f56', text=\"LlamaIndex news, 2023-11-14 Hello Llama Friends ü¶ô LlamaIndex is 1 year old this week! üéâ To celebrate, we're taking a stroll down memory \\n                    lane on our blog with twelve milestones from our first year. Be sure to check it out. \", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.03225806451612903)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = PersonalAssistantVespaRetriever(\n",
    "    app=app, \n",
    "    user=\"bergum@vespa.ai\", \n",
    "    vespa_rank_profile=\"fusion\"\n",
    ")\n",
    "retriever.retrieve(\"When is my dentist appointment?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b8223",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "With a custom retriever one like above, one can start experimenting with [LLamaIndex](https://gpt-index.readthedocs.io/en/stable/) to build \n",
    "the personal agent. With Vespa streaming mode, the cost of searching personal data is several orders\n",
    "lower than personal search built using ANN algorithms as no fields are in-memory and everything is streamed from disk based storage. \n",
    "\n",
    "\n",
    "We can now delete the cloud instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71e310e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deactivated samples.assistant in dev.aws-us-east-1c\n",
      "Deleted instance samples.assistant.default\n"
     ]
    }
   ],
   "source": [
    "vespa_cloud.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
