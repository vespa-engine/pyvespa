{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "given-adoption",
   "metadata": {},
   "source": [
    "![Vespa logo](https://vespa.ai/assets/vespa-logo-color.png)\n",
    "\n",
    "# Hybrid Search - Quickstart\n",
    "\n",
    "This tutorial creates a hybrid text search application combining traditional keyword matching\n",
    "with semantic vector search (dense retrieval). It also demonstrates using \n",
    "[Vespa native embedder](https://docs.vespa.ai/en/embedding.html) functionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c967bd2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Refer to <a href=\"https://pyvespa.readthedocs.io/en/latest/troubleshooting.html\">troubleshooting</a>\n",
    "    for any problem when running this guide.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345b2fe",
   "metadata": {},
   "source": [
    "[Install pyvespa](https://pyvespa.readthedocs.io/) and start Docker Daemon, validate minimum 6G available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f3d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyvespa\n",
    "!docker info | grep \"Total Memory\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db637322",
   "metadata": {},
   "source": [
    "## Create an application package\n",
    "\n",
    "The [application package](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.package.ApplicationPackage)\n",
    "has all the Vespa configuration files -\n",
    "create one from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5c2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage, Field, Schema, Document, RankProfile, HNSW, RankProfile, Component, Parameter, FieldSet, GlobalPhaseRanking, Function\n",
    "\n",
    "package = ApplicationPackage(\n",
    "        name=\"hybridsearch\",\n",
    "        schema=[Schema(\n",
    "            name=\"doc\",\n",
    "            document=Document(\n",
    "                fields=[\n",
    "                    Field(name=\"id\", type=\"string\", indexing=[\"summary\"]),\n",
    "                    Field(name=\"title\", type=\"string\", indexing=[\"index\", \"summary\"], index=\"enable-bm25\"),\n",
    "                    Field(name=\"body\", type=\"string\", indexing=[\"index\", \"summary\"], index=\"enable-bm25\", bolding=True),\n",
    "                    Field(name=\"embedding\", type=\"tensor<float>(x[384])\",\n",
    "                        indexing=[\"input title . \\\" \\\" . input body\", \"embed\", \"index\", \"attribute\"],\n",
    "                        ann=HNSW(distance_metric=\"angular\"),\n",
    "                        is_document_field=False\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            fieldsets=[\n",
    "                FieldSet(name = \"default\", fields = [\"title\", \"body\"])\n",
    "            ],\n",
    "            rank_profiles=[\n",
    "                RankProfile(\n",
    "                    name=\"bm25\", \n",
    "                    inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "                    functions=[Function(\n",
    "                        name=\"bm25sum\", expression=\"bm25(title) + bm25(body)\"\n",
    "                    )],\n",
    "                    first_phase=\"bm25sum\"\n",
    "                ),\n",
    "                RankProfile(\n",
    "                    name=\"semantic\", \n",
    "                    inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "                    first_phase=\"closeness(field, embedding)\"\n",
    "                ),\n",
    "                RankProfile(\n",
    "                    name=\"fusion\", \n",
    "                    inherits=\"bm25\",\n",
    "                    inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "                    first_phase=\"closeness(field, embedding)\",\n",
    "                    global_phase=GlobalPhaseRanking(\n",
    "                        expression=\"reciprocal_rank_fusion(bm25sum, closeness(field, embedding))\",\n",
    "                        rerank_count=1000\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        ],\n",
    "        components=[Component(id=\"e5\", type=\"hugging-face-embedder\",\n",
    "            parameters=[\n",
    "                Parameter(\"transformer-model\", {\"url\": \"https://github.com/vespa-engine/sample-apps/raw/master/simple-semantic-search/model/e5-small-v2-int8.onnx\"}),\n",
    "                Parameter(\"tokenizer-model\", {\"url\": \"https://raw.githubusercontent.com/vespa-engine/sample-apps/master/simple-semantic-search/model/tokenizer.json\"})\n",
    "            ]\n",
    "        )]\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e2943",
   "metadata": {},
   "source": [
    "Note that the name cannot have `-` or `_`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-savage",
   "metadata": {},
   "source": [
    "## Deploy the Vespa application \n",
    "\n",
    "Deploy `package` on the local machine using Docker,\n",
    "without leaving the notebook, by creating an instance of\n",
    "[VespaDocker](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.deployment.VespaDocker). `VespaDocker` connects\n",
    "to the local Docker daemon socket and starts the [Vespa docker image](https://hub.docker.com/r/vespaengine/vespa/). \n",
    "\n",
    "If this step fails, please check\n",
    "that the Docker daemon is running, and that the Docker daemon socket can be used by clients (Configurable under advanced settings in Docker Desktop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "canadian-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy(application_package=package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae2f91",
   "metadata": {},
   "source": [
    "`app` now holds a reference to a [Vespa](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.application.Vespa) instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-mustang",
   "metadata": {},
   "source": [
    "## Feeding documents to Vespa\n",
    "\n",
    "In this example we use the [HF Datasets](https://huggingface.co/docs/datasets/index) library to stream the\n",
    "[BeIR/nfcorpus](https://huggingface.co/datasets/BeIR/nfcorpus) dataset and index in our newly deployed Vespa instance. Read\n",
    "more about the [NFCorpus](https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/):\n",
    "\n",
    ">NFCorpus is a full-text English retrieval data set for Medical Information Retrieval. \n",
    "\n",
    "The following uses the [stream](https://huggingface.co/docs/datasets/stream) option of datasets to stream the data without\n",
    "downloading all the contents locally. The `map` functionality allows us to convert the\n",
    "dataset fields into the expected feed format for `pyvespa` which expects a dict with the keys `id` and `fields`:\n",
    "\n",
    "` {Â \"id\": \"vespa-document-id\", \"fields\": {\"vespa_field\": \"vespa-field-value\"}} `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d3facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"BeIR/nfcorpus\", \"corpus\", split=\"corpus\", streaming=True)\n",
    "vespa_feed = dataset.map(lambda x: {\"id\": x[\"_id\"], \"fields\": { \"title\": x[\"title\"], \"body\": x[\"text\"], \"id\": x[\"_id\"]}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6bc25",
   "metadata": {},
   "source": [
    "Now we can feed to Vespa using `feed_iterable` which accepts any `Iterable` and an optional callback function where we can\n",
    "check the outcome of each operation. The application is configured to use [embedding](https://docs.vespa.ai/en/embedding.html)\n",
    "functionality, that produce a vector embedding using a concatenation of the title and the body input fields. This step is computionally expensive. Read more\n",
    "about embedding inference in Vespa in the [Accelerating Transformer-based Embedding Retrieval with Vespa](https://blog.vespa.ai/accelerating-transformer-based-embedding-retrieval-with-vespa/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7429132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.io import VespaResponse, VespaQueryResponse\n",
    "\n",
    "def callback(response:VespaResponse, id:str):\n",
    "    if not response.is_successful():\n",
    "        print(f\"Error when feeding document {id}: {response.get_json()}\")\n",
    "\n",
    "app.feed_iterable(vespa_feed, schema=\"doc\", namespace=\"tutorial\", callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-insertion",
   "metadata": {},
   "source": [
    "## Querying Vespa\n",
    "\n",
    "Using the [Vespa Query language](https://docs.vespa.ai/en/query-language.html) we can query the indexed data. \n",
    "\n",
    "- Using a context manager `with app.syncio() as session` to handle connection pooling ([best practices](https://cloud.vespa.ai/en/http-best-practices))\n",
    "- The query method accepts any valid Vespa [query api parameter](https://docs.vespa.ai/en/reference/query-api-reference.html) in `**kwargs`\n",
    "- Vespa api parameter names that contains `.` must be sent as `dict` parameters in the `body` method argument\n",
    "\n",
    "The following searches for `How Fruits and Vegetables Can Treat Asthma?` using different retrieval and [ranking](https://docs.vespa.ai/en/ranking.html) strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20306d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def display_hits_as_df(response:VespaQueryResponse, fields) -> pd.DataFrame:\n",
    "    records = []\n",
    "    for hit in response.hits:\n",
    "        record = {}\n",
    "        for field in fields:\n",
    "            record[field] = hit['fields'][field]\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2798ec5c",
   "metadata": {},
   "source": [
    "### Plain Keyword search \n",
    "The following uses plain keyword search functionality with [bm25](https://docs.vespa.ai/en/reference/bm25.html) ranking, the `bm25` rank-profile was configured in the \n",
    "application package to use a linear combination of the bm25 score of the query terms against the title and the body field. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be392a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"How Fruits and Vegetables Can Treat Asthma?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where userQuery() limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"bm25\"\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3932b3",
   "metadata": {},
   "source": [
    "### Plain Semantic Search \n",
    "The following uses dense vector representations of the query and the document and matching is performed and accelerated by Vespa's support for\n",
    "[approximate nearest neighbor search](https://docs.vespa.ai/en/approximate-nn-hnsw.html). \n",
    "The vector embedding representation of the text is obtained using Vespa's [embedder functionality](https://docs.vespa.ai/en/embedding.html#embedding-a-query-text).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6f0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"How Fruits and Vegetables Can Treat Asthma?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where ({targetHits:1000}nearestNeighbor(embedding,q)) limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"semantic\", \n",
    "    body = {\n",
    "      \"input.query(q)\": f\"embed({query})\"\n",
    "    }\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd25020",
   "metadata": {},
   "source": [
    "### Hybrid Search\n",
    "\n",
    "This is one approach to combine the two retrieval strategies and where we use Vespa's support for \n",
    "[cross-hits feature normalization and reciprocal rank fusion](https://docs.vespa.ai/en/phased-ranking.html#cross-hit-normalization-including-reciprocal-rank-fusion). This\n",
    "functionality is exposed in the context of `global` re-ranking, after the distributed query retrieval execution which might span 1000s of nodes. \n",
    "\n",
    "#### Hybrid search with the OR query operator\n",
    "\n",
    "This combines the two methods using logical disjunction (OR). Note that the first-phase expression in our `fusion` expression is only using the semantic score, this \n",
    "because usually semantic search provides better recall than sparse keyword search alone. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b5f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"How Fruits and Vegetables Can Treat Asthma?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where userQuery() or ({targetHits:1000}nearestNeighbor(embedding,q)) limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"fusion\", \n",
    "    body = {\n",
    "      \"input.query(q)\": f\"embed({query})\"\n",
    "    }\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa4eb0",
   "metadata": {},
   "source": [
    "#### Hybrid search with the RANK query operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9e77a",
   "metadata": {},
   "source": [
    "This combines the two methods using the [rank](https://docs.vespa.ai/en/reference/query-language-reference.html#rank) query operator. In this case\n",
    "we express that we want to retrieve the top-1000 documents using vector search, and then have sparse features like BM25 calculated as well (second operand \n",
    "of the rank operator). Finally the hits are re-ranked using the reciprocal rank fusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb84a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"How Fruits and Vegetables Can Treat Asthma?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where rank({targetHits:1000}nearestNeighbor(embedding,q), userQuery()) limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"fusion\", \n",
    "    body = {\n",
    "      \"input.query(q)\": f\"embed({query})\"\n",
    "    }\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457aefc",
   "metadata": {},
   "source": [
    "#### Hybrid search with filters\n",
    "\n",
    "In this example we add another query term to the yql, restricting the nearest neighbor search to only consider documents that have vegetable in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b341042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "  query = \"How Fruits and Vegetables Can Treat Asthma?\"\n",
    "  response:VespaQueryResponse = session.query(\n",
    "    yql=\"select * from sources * where title contains \\\"vegetable\\\" and rank({targetHits:1000}nearestNeighbor(embedding,q), userQuery()) limit 5\", \n",
    "    query=query, \n",
    "    ranking=\"fusion\", \n",
    "    body = {\n",
    "      \"input.query(q)\": f\"embed({query})\"\n",
    "    }\n",
    "  )\n",
    "  assert(response.is_successful())\n",
    "  print(display_hits_as_df(response, [\"id\", \"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28591491",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5064bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vespa_docker.container.stop()\n",
    "vespa_docker.container.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1872b31",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This is just an intro into the capabilities of Vespa and pyvespa.\n",
    "Browse the site to learn more about schemas, feeding and queries - \n",
    "find more complex applications in\n",
    "[examples](https://pyvespa.readthedocs.io/en/latest/examples.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
