{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floating-subsection",
   "metadata": {},
   "source": [
    "![Vespa logo](https://vespa.ai/assets/vespa-logo-color.png)\n",
    "\n",
    "# Read and write operations\n",
    "\n",
    "This notebook documents ways to feed, get, update and delete data:\n",
    "\n",
    "* Using context manager with `with` for efficiently managing resources \n",
    "* Feeding streams of data using `feed_iter` which can feed from streams, Iterables, Lists and files by the use of generators "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc991f44",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Refer to <a href=\"https://pyvespa.readthedocs.io/en/latest/troubleshooting.html\">troubleshooting</a>\n",
    "    for any problem when running this guide.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549a74f",
   "metadata": {},
   "source": [
    "## Deploy a sample application\n",
    "\n",
    "[Install pyvespa](https://pyvespa.readthedocs.io/) and start Docker, validate minimum 4G available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166bc50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker info | grep \"Total Memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11c7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Specify the directory you want to prepend to sys.path\n",
    "directory_to_prepend = \"/Users/bergum/git/pyvespa/\"\n",
    "\n",
    "# Prepend the directory to sys.path\n",
    "sys.path.insert(0, directory_to_prepend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4538e7b2",
   "metadata": {},
   "source": [
    "Define a simple application package with five fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "congressional-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.application import ApplicationPackage\n",
    "from vespa.package import Schema, Document, Field, FieldSet, HNSW, RankProfile\n",
    "\n",
    "app_package = ApplicationPackage(\n",
    "        name=\"vector\",\n",
    "        schema=[Schema(\n",
    "            name=\"doc\",\n",
    "            document=Document(\n",
    "                fields=[\n",
    "                    Field(name=\"id\", type=\"string\", indexing=[\"attribute\", \"summary\"]),\n",
    "                    Field(name=\"title\", type=\"string\", indexing=[\"index\", \"summary\"], index=\"enable-bm25\"),\n",
    "                    Field(name=\"body\", type=\"string\", indexing=[\"index\", \"summary\"], index=\"enable-bm25\"),\n",
    "                    Field(name=\"popularity\", type=\"float\", indexing=[\"attribute\", \"summary\"]),\n",
    "                    Field(\n",
    "                        name=\"embedding\",\n",
    "                        type=\"tensor<bfloat16>(x[1536])\",\n",
    "                        indexing=[\"attribute\", \"summary\", \"index\"],\n",
    "                        ann=HNSW(\n",
    "                            distance_metric=\"innerproduct\",\n",
    "                            max_links_per_node=16,\n",
    "                            neighbors_to_explore_at_insert=128,\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            fieldsets=[\n",
    "                    FieldSet(name = \"default\", fields = [\"title\", \"body\"])\n",
    "            ],\n",
    "            rank_profiles=[\n",
    "                RankProfile(\n",
    "                    name=\"default\", \n",
    "                    inputs=[(\"query(q)\", \"tensor<float>(x[1536])\")],\n",
    "                    first_phase=\"closeness(field, embedding)\"\n",
    "                )\n",
    "            ])\n",
    "        ]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eff8bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Application is up!\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy(application_package=app_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-wound",
   "metadata": {},
   "source": [
    "## Feed data by streaming over Iterable type\n",
    "\n",
    "This example notebook uses the [dbpedia-entities-openai-1M](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M) \n",
    "dataset (1M OpenAI Embeddings (1536 dimensions) from June 2023). \n",
    "\n",
    "The `streaming=True` option allow paging the data on-demand from HF S3. \n",
    "This is extremely useful for large datasets, where the data does not fit in memory\n",
    "and downloading the entire dataset is not needed.\n",
    "Read more about [datasets stream](https://huggingface.co/docs/datasets/stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "breeding-steal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551ee17d4baf4c06bbb365254279f9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"KShivendu/dbpedia-entities-openai-1M\", split=\"train\", streaming=True).take(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afda75a",
   "metadata": {},
   "source": [
    "### Converting to dataset field names to Vespa schema field names\n",
    "We need to convert the dataset field names to the configured Vespa schema field names, we do this with a simple lambda function. \n",
    "\n",
    "The map function does not page the data, the map step is performed lazily if we start iterating over the dataset. \n",
    "This allows chaining of map operations where the lambda is yielding the next document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04503d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvespa_feed_format = dataset.map(lambda x: {\"id\": x[\"_id\"], \"fields\": {\"id\": x[\"_id\"], \"embedding\":x[\"openai\"]}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-dominant",
   "metadata": {},
   "source": [
    "Feed using [feed_iterable](https://pyvespa.readthedocs.io/en/latest/reference-api.html#vespa.application.Vespa.feed_iterable) which \n",
    "accepts an `Iterable`. `feed_iterable` accepts a callback callable routine that is called for every single data operation so we can \n",
    "check the result. If the result `is_successful()` the operation is persisted and applied in Vespa.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "meaning-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.io import VespaResponse\n",
    "\n",
    "def callback(response:VespaResponse, id:str):\n",
    "    if not response.is_successfull():\n",
    "        print(f\"Failed to feed document {id} with status code {response.status_code}: Reason {response.get_json()}\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98533b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.feed_iterable(\n",
    "    iter=pyvespa_feed_format, \n",
    "    schema=\"doc\", namespace=\"benchmark\", \n",
    "    callback=callback, \n",
    "    max_queue_size=4000, max_workers=16, max_connections=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c6b7a",
   "metadata": {},
   "source": [
    "### Feeding with generators\n",
    "The above handled streaming data from a remote repo, we can also use generators or just List. In this example, we generate synthetic data\n",
    "using a generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03420d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator() -> dict:\n",
    "    for i in range(1000):\n",
    "        yield {\"id\": str(i), \"fields\": {\"id\": str(i), \"title\": \"title\", \"body\": \"this is body\", \"popularity\": 1.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6acf364",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.feed_iterable(\n",
    "    iter=my_generator(), \n",
    "    schema=\"doc\", namespace=\"benchmark\", \n",
    "    callback=callback, \n",
    "    max_queue_size=4000, max_workers=12, max_connections=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a74ca6",
   "metadata": {},
   "source": [
    "### Updates \n",
    "Using a similar generator we can update the fake data we added. This performs \n",
    "[partial updates](https://docs.vespa.ai/en/partial-updates.html), assigning the `popularity` field to have the value `2.0`.  \n",
    "\n",
    "Note that PyVespa only supports `assign` type of [partial updates](https://docs.vespa.ai/en/reference/document-json-format.html#update)\n",
    "and will automatically rewrite an update operation with fields like this \n",
    "\n",
    "```\n",
    " \"fields\": {\n",
    "    \"title\":\"The best of Bob Dylan\"\n",
    "  }\n",
    "```\n",
    "\n",
    "To the correct JSON update syntax expected by Vespa:\n",
    "\n",
    "```\n",
    " \"fields\": {\n",
    "        \"title\": {\n",
    "            \"assign\": \"The best of Bob Dylan\"\n",
    "        }\n",
    "}\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93b342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_update_generator() -> dict:\n",
    "    for i in range(1000):\n",
    "        yield {\"id\": str(i), \"fields\": {\"popularity\": 2.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bde61e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.feed_iterable(\n",
    "    iter=my_update_generator(), \n",
    "    schema=\"doc\", namespace=\"benchmark\", \n",
    "    callback=callback, operation_type=\"update\", \n",
    "    max_queue_size=4000, max_workers=12, max_connections=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d630e",
   "metadata": {},
   "source": [
    "We can now query the data, notice how we use a context manager `with` to close connection after query \n",
    "This avoids resource leakage and allows for reuse of connections. In this case, we only do a single \n",
    "query and there is no need for having more than one connection. Setting more connections will just \n",
    "increase connection level overhead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f7046c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "from vespa.io import VespaQueryResponse\n",
    "\n",
    "with app.syncio(connections=1):\n",
    "    response: VespaQueryResponse = app.query(yql=\"select id from doc where popularity > 1.5\", hits=0)\n",
    "    print(response.number_documents_retrieved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862389c",
   "metadata": {},
   "source": [
    "### Deleting\n",
    "Delete all the synthetic data with a custom generator. Now we don't need the `fields` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb07d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_delete_generator() -> dict:\n",
    "    for i in range(1000):\n",
    "        yield {\"id\": str(i)}\n",
    "\n",
    "app.feed_iterable(\n",
    "    iter=my_delete_generator(), \n",
    "    schema=\"doc\", namespace=\"benchmark\", \n",
    "    callback=callback, operation_type=\"delete\",\n",
    "    max_queue_size=5000, max_workers=48, max_connections=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba676a1",
   "metadata": {},
   "source": [
    "## Feeding operations from a file\n",
    "\n",
    "This demonstrates how we can use `feed_iter` to feed from a large file without reading the entire file, this also\n",
    "uses a generator. \n",
    "\n",
    "First we dump some operations to the file and peak at the first line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac79662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dump some operation to a jsonl file, we store it in the format expected by pyvespa\n",
    "#This to demonstrate feeding from a file in the next section.\n",
    "import json\n",
    "with open(\"documents.jsonl\", \"w\") as f:\n",
    "    for doc in dataset:\n",
    "        d = {\"id\": doc[\"_id\"], \"fields\": {\"id\": doc[\"_id\"], \"embedding\":doc[\"openai\"]}}\n",
    "        f.write(json.dumps(d) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfabfbc",
   "metadata": {},
   "source": [
    "Define the file generator that will yield one line at a time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2422af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def from_file_generator() -> dict:\n",
    "    with open(\"documents.jsonl\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab731c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.feed_iterable(\n",
    "    iter=from_file_generator(),\n",
    "    schema=\"doc\",\n",
    "    namespace=\"benchmark\",\n",
    "    callback=callback,\n",
    "    operation_type=\"feed\",\n",
    "    max_queue_size=4000,\n",
    "    max_workers=32,\n",
    "    max_connections=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e22de",
   "metadata": {},
   "source": [
    "### Get and Feed individual data points\n",
    "\n",
    "Feed a single data point to Vespa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b598b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1):\n",
    "    response: VespaResponse = app.feed_data_point(\n",
    "        schema=\"doc\",\n",
    "        namespace=\"benchmark\",\n",
    "        data_id=\"1\",\n",
    "        fields={\n",
    "            \"id\": \"1\",\n",
    "            \"title\": \"title\",\n",
    "            \"body\": \"this is body\",\n",
    "            \"popularity\": 1.0,\n",
    "        }\n",
    "    )\n",
    "    print(response.is_successfull())\n",
    "    print(response.get_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f4deae",
   "metadata": {},
   "source": [
    "Get the same document, try also to change data_id to a document that does not exist which will raise a 404 http error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1):\n",
    "    response: VespaResponse = app.get_data(\n",
    "        schema=\"doc\",\n",
    "        namespace=\"benchmark\",\n",
    "        data_id=\"1\",\n",
    "    )\n",
    "    print(response.is_successfull())\n",
    "    print(response.get_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0841a4c",
   "metadata": {},
   "source": [
    "### Upsert\n",
    "\n",
    "The following sends an update operation, if the document exist, the popularity field will be updated to take the value 3.0, and if the document\n",
    "does not exist, it's created and where the popularity value is 3.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e52e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1):\n",
    "    response: VespaResponse = app.update_data(\n",
    "        schema=\"doc\",\n",
    "        namespace=\"benchmark\",\n",
    "        data_id=\"does-not-exist\",\n",
    "        fields={ \"popularity\": 3.0 }, \n",
    "        create=True\n",
    "    )\n",
    "    print(response.is_successfull())\n",
    "    print(response.get_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.syncio(connections=1):\n",
    "    response: VespaResponse = app.get_data(\n",
    "        schema=\"doc\",\n",
    "        namespace=\"benchmark\",\n",
    "        data_id=\"does-not-exist\",\n",
    "    )\n",
    "    print(response.is_successfull())\n",
    "    print(response.get_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaff1d1",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "vespa_docker.container.stop()\n",
    "vespa_docker.container.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc7079",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Read more on writing to Vespa in [reads-and-writes](https://docs.vespa.ai/en/reads-and-writes.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
