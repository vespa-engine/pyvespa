{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distributed-means",
   "metadata": {},
   "source": [
    "# Sequence Classification task\n",
    "\n",
    "Vespa has [recently implemented](https://blog.vespa.ai/stateless-model-evaluation/)\n",
    "accelerated model evaluation using ONNX Runtime in the stateless cluster.\n",
    "This opens up new usage areas for Vespa, such as serving model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-bachelor",
   "metadata": {},
   "source": [
    "## Define the model server\n",
    "\n",
    "Define the task and the model to use. The [SequenceClassification](https://pyvespa.readthedocs.io/en/latest/reference-api.html#sequenceclassification) task takes a text input and return an array of floats that depends on the model used to solve the task. The `model` argument can be the id of the model as defined by the huggingface model hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedicated-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.ml import SequenceClassification\n",
    "\n",
    "task = SequenceClassification(\n",
    "    model_id=\"bert_tiny\", \n",
    "    model=\"google/bert_uncased_L-2_H-128_A-2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-robinson",
   "metadata": {},
   "source": [
    "A `ModelServer` is a simplified application package focused on stateless model evaluation. It can take as many tasks as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cloudy-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ModelServer\n",
    "\n",
    "model_server = ModelServer(\n",
    "    name=\"bert_model_server\",\n",
    "    tasks=[task],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-blair",
   "metadata": {},
   "source": [
    "## Deploy the model server\n",
    "\n",
    "We can either host our model server on Vespa Cloud or deploy it locally using a Docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-conjunction",
   "metadata": {},
   "source": [
    "### Host it on VespaCloud\n",
    "\n",
    "Check [this short guide](https://pyvespa.readthedocs.io/en/latest/deploy-vespa-cloud.html)\n",
    "for detailed information about how to setup your Vespa Cloud account\n",
    "and where to find the environment variables defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spread-transport",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TENANT_NAME\"] = \"vespa-team\"\n",
    "os.environ[\"APPLICATION_NAME\"] = \"pyvespa-integration\"\n",
    "if (os.getenv(\"VESPA_CLOUD_USER_KEY\")):\n",
    "    with open(os.path.join(os.getenv(\"WORK_DIR\"), \"key.pem\"), \"w\") as f:\n",
    "        f.write(os.getenv(\"VESPA_CLOUD_USER_KEY\").replace(r\"\\n\", \"\\n\"))\n",
    "    os.environ[\"USER_KEY\"] = os.path.join(os.getenv(\"WORK_DIR\"), \"key.pem\")\n",
    "    os.environ[\"INSTANCE_NAME\"] = \"test\"\n",
    "os.environ[\"DISK_FOLDER\"] = os.path.join(os.getenv(\"WORK_DIR\"), \"sample_application\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.deployment import VespaCloud\n",
    "\n",
    "if (os.getenv(\"VESPA_CLOUD_USER_KEY\")):\n",
    "    vespa_cloud = VespaCloud(\n",
    "        tenant=os.getenv(\"TENANT_NAME\"),\n",
    "        application=os.getenv(\"APPLICATION_NAME\"),\n",
    "        key_location=os.getenv(\"USER_KEY\"),\n",
    "        application_package=model_server,\n",
    "    )\n",
    "    app = vespa_cloud.deploy(\n",
    "        instance=os.getenv(\"INSTANCE_NAME\"), disk_folder=os.getenv(\"DISK_FOLDER\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-freeware",
   "metadata": {},
   "source": [
    "### Deploy locally\n",
    "\n",
    "Similarly, we can deploy the model server locally in a Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker(disk_folder=os.getenv(\"DISK_FOLDER\"), port=8081)\n",
    "app = vespa_docker.deploy(application_package=model_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-cleanup",
   "metadata": {},
   "source": [
    "## Get model information\n",
    "\n",
    "Get models available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lovely-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_tiny': 'http://localhost:8081/model-evaluation/v1/bert_tiny'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.get_model_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-wells",
   "metadata": {},
   "source": [
    "Get information about a specific model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "digital-sewing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'bert_tiny',\n",
       " 'functions': [{'function': 'output_0',\n",
       "   'info': 'http://localhost:8081/model-evaluation/v1/bert_tiny/output_0',\n",
       "   'eval': 'http://localhost:8081/model-evaluation/v1/bert_tiny/output_0/eval',\n",
       "   'arguments': [{'name': 'input_ids', 'type': 'tensor(d0[],d1[])'},\n",
       "    {'name': 'attention_mask', 'type': 'tensor(d0[],d1[])'},\n",
       "    {'name': 'token_type_ids', 'type': 'tensor(d0[],d1[])'}]}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.get_model_endpoint(model_id=\"bert_tiny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-behalf",
   "metadata": {},
   "source": [
    "## Get predictions\n",
    "\n",
    "Get a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "significant-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.053629081696271896, -0.01650623418390751]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.predict(x=\"this is a test\", model_id=\"bert_tiny\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
